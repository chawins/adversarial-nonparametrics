{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import logging\n",
    "from functools import reduce, partial\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Union, Callable\n",
    "import pprint\n",
    "from mkdir_p import mkdir_p\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from nnattack.variables import auto_var\n",
    "from params import (\n",
    "    compare_attacks,\n",
    "    compare_defense,\n",
    "    parametric_defense,\n",
    "    \n",
    "    compare_nns,\n",
    "    \n",
    "    nn_k1_robustness,\n",
    "    nn_k3_robustness,\n",
    "    rf_robustness,\n",
    "    dt_robustness,\n",
    "    lr_ap_robustness,\n",
    "    lr_at_robustness,\n",
    "    mlp_ap_robustness,\n",
    "    mlp_at_robustness,\n",
    "    \n",
    "    tst_scores,\n",
    "    \n",
    "    dt_robustness_figs,\n",
    "    nn_k1_robustness_figs,\n",
    "    nn_k3_robustness_figs,\n",
    "    rf_robustness_figs,\n",
    "    rf_optimality_figs,\n",
    "    nn_k1_optimality_figs,\n",
    "    nn_k3_optimality_figs,\n",
    ")\n",
    "from utils import set_plot, get_result, write_to_tex, union_param_key, params_to_dataframe, table_wrapper\n",
    "\n",
    "auto_var.set_variable_value('random_seed', 0)\n",
    "auto_var.set_variable_value('ord', 'inf')\n",
    "auto_var.set_logging_level(0)\n",
    "\n",
    "compare_attacks = compare_attacks()\n",
    "compare_defense = compare_defense()\n",
    "parametric_defense = parametric_defense()\n",
    "tst_scores = tst_scores()\n",
    "\n",
    "compare_nns = compare_nns()\n",
    "mlp_ap_robustness = mlp_ap_robustness()\n",
    "mlp_at_robustness = mlp_at_robustness()\n",
    "lr_ap_robustness = lr_ap_robustness()\n",
    "lr_at_robustness = lr_at_robustness()\n",
    "nn_k1_robustness = nn_k1_robustness()\n",
    "nn_k3_robustness = nn_k3_robustness()\n",
    "rf_robustness = rf_robustness()\n",
    "dt_robustness = dt_robustness()\n",
    "dt_robustness_figs = dt_robustness_figs()\n",
    "nn_k1_robustness_figs = nn_k1_robustness_figs()\n",
    "nn_k3_robustness_figs = nn_k3_robustness_figs()\n",
    "rf_optimality_figs = rf_optimality_figs()\n",
    "nn_k1_optimality_figs = nn_k1_optimality_figs()\n",
    "nn_k3_optimality_figs = nn_k3_optimality_figs()\n",
    "rf_robustness_figs = rf_robustness_figs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_latex_figs(exp_name, control_var, caption):\n",
    "    control = ParameterGrid(control_var)\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for i, g in enumerate(control):\n",
    "        dataset, ord = g['dataset'], g['ord']\n",
    "        img_path = f'./figs/{exp_name}_{dataset}_{ord}.eps'\n",
    "        dataset = dataset.replace(\"_\", \" \")\n",
    "        ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=.45\\\\textwidth]{%s}}\"\"\" % (dataset, img_path)\n",
    "        if i % 2 == 1:\n",
    "            ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, exp_name)\n",
    "    return ret\n",
    "                      \n",
    "def plot_result(df, exp_name, control_var, variables,\n",
    "                get_title_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_name_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_color_fn: Union[Callable[[Dict], str], None]=None, show_plot=True):\n",
    "    ret = []\n",
    "    for g in ParameterGrid(control_var):\n",
    "        temp_df = df\n",
    "                      \n",
    "        if get_title_fn is None:\n",
    "            title = exp_name\n",
    "            for k, v in g.items():\n",
    "                if v in variable_name[k]:\n",
    "                    title = title + f\"_{variable_name[k][v]}\"\n",
    "                else:\n",
    "                    title = title + f\"_{v}\"\n",
    "        else:\n",
    "            title = get_title_fn(g)\n",
    "            \n",
    "        for k, v in g.items():\n",
    "            temp_df = temp_df.loc[df[k] == v]\n",
    "                      \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(title)\n",
    "        for name, group in temp_df.groupby(variables):\n",
    "            #print(name, len(group))\n",
    "            eps_list = [re.findall(r'[-+]?\\d*\\.\\d+|\\d+', t)[0] for t in group.mean().index.tolist()[:-1]]\n",
    "            s = [r for r in group.mean().tolist()[:-1] if not np.isnan(r)]\n",
    "            x = [float(eps_list[i]) for i, r in enumerate(group.mean().tolist()[:-1]) if not np.isnan(r)]\n",
    "                      \n",
    "            if get_label_name_fn is not None:\n",
    "                label = get_label_name(name)\n",
    "            elif isinstance(name, str):\n",
    "                if variables[0] not in variable_name:\n",
    "                    label = name\n",
    "                elif name in variable_name[variables[0]]:\n",
    "                    label = variable_name[variables[0]][name]\n",
    "                else:\n",
    "                    label = name\n",
    "            else:\n",
    "                mod_names = []\n",
    "                for i, n in enumerate(name):\n",
    "                    if n in variable_name[variables[i]]:\n",
    "                        mod_names.append(variable_name[variables[i]][n])\n",
    "                    else:\n",
    "                        mod_names.append(n)\n",
    "                label = mod_name.join(\"_\")\n",
    "\n",
    "            if get_label_color_fn is not None:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5, color=get_label_color_fn(name))\n",
    "            else:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5)\n",
    "\n",
    "        dataset = g['dataset']\n",
    "        ord = g['ord']\n",
    "        set_plot(fig, ax)\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        ret.append((g, f'./figs/{exp_name}_{dataset}_{ord}.eps'))\n",
    "        if show_plot:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    return ret\n",
    "                      \n",
    "variable_name = {\n",
    "    'attack': {\n",
    "        'blackbox': 'Cheng\\'s',\n",
    "        'kernelsub_c10000_pgd': 'kernelsub',\n",
    "        'kernelsub_c1000_pgd': 'kernelsub',\n",
    "        'rev_nnopt_k1_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k1_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k1_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k1_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k3_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k3_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k3_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k3_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k5_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k5_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k5_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k5_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k7_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k7_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k7_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k7_50_region': 'nnopt-50',\n",
    "        \n",
    "        'nnopt_k1_all': 'nnopt-all',\n",
    "        'nnopt_k3_all': 'nnopt-all',\n",
    "        \n",
    "        'direct_k1': 'direct attack',\n",
    "        'direct_k3': 'direct attack',\n",
    "        'direct_k5': 'direct attack',\n",
    "        'direct_k7': 'direct attack',\n",
    "        \n",
    "        'rf_attack_all': 'RF-all',\n",
    "        'rf_attack_rev': 'RF-rev',\n",
    "        'rf_attack_rev_20': 'RF-rev-20',\n",
    "        'rf_attack_rev_50': 'RF-rev-50',\n",
    "        'rf_attack_rev_100': 'RF-rev-100',\n",
    "    },\n",
    "    'ord': {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parbox(width, content):\n",
    "    return \"\\\\parbox{%dmm}{\\\\centering %s}\" % (width, content)\n",
    "\n",
    "def knn_attack_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['attack']\n",
    "    plot_result(df, exp_name, control, variables, show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "\n",
    "def get_var_name(var, arg):\n",
    "    if var == 'dataset':\n",
    "        return auto_var.get_var_shown_name(var, arg)\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def avg_pert_table(exp_name, grid_param, columns, rows, objs:list=None, obj_formats:list=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    columns = list(filter(lambda a: a not in ['n_features', 'n_samples', 'n_classes'], columns))\n",
    "    if len(columns) == 0 or len(rows) == 0:\n",
    "        return pd.DataFrame({})\n",
    "    df = params_to_dataframe(grid_param, objs)\n",
    "    \n",
    "    d = OrderedDict()\n",
    "    col_grid = OrderedDict([(c, union_param_key(grid_param, c)) for c in columns])\n",
    "    row_grid = OrderedDict([(r, union_param_key(grid_param, r)) for r in rows])\n",
    "    for i, obj in enumerate(objs):\n",
    "        temp_df = df.groupby(columns + rows)[obj].mean()\n",
    "        temp_df_sem = df.groupby(columns + rows)[obj].sem()\n",
    "        \n",
    "        if obj == 'tst_score':\n",
    "            assert columns[0] == 'model'\n",
    "        for col in ParameterGrid(col_grid):\n",
    "            col_k = tuple(col[c] for c in columns)\n",
    "            col_name = tuple([get_var_name(c, col[c]) for c in columns[:-1]] \\\n",
    "                             + [\"%s-%s\" % (get_var_name(columns[-1], col[columns[-1]]), obj.replace(\"_\", \"-\"))])\n",
    "            d[col_name] = {}\n",
    "            for row in ParameterGrid(row_grid):\n",
    "                row_k = tuple(row[r] for r in rows)\n",
    "                row_name = tuple(get_var_name(r, row[r]) for r in rows)\n",
    "                if (col_k + row_k) in temp_df:\n",
    "                    #d[col_name][row_name] = \"$%.3f \\pm %.3f$\" % (temp_df[col_k + row_k], temp_df_sem[col_k + row_k])\n",
    "                    if obj_formats is None:\n",
    "                        str_format = \"$%.3f$\"\n",
    "                    else:\n",
    "                        str_format = obj_formats[i]\n",
    "                    d[col_name][row_name] = str_format % (temp_df[col_k + row_k])\n",
    "                    if temp_df[col_k + row_k] < 1:\n",
    "                        d[col_name][row_name] = d[col_name][row_name].replace(\"0.\", \".\")\n",
    "                else:\n",
    "                    d[col_name][row_name] = -1\n",
    "\n",
    "    #d = OrderedDict([(k, d[k]) for k in d.keys()])\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def dataset_stat_column(df, grid_param, columns, rows):\n",
    "    if (\"n_features\" not in columns) and (\"n_samples\" not in columns) and (\"n_classes\" not in columns) \\\n",
    "        and (\"n_train\" not in columns) and (\"n_test\" not in columns):\n",
    "        return df\n",
    "    \n",
    "    column_names = {\n",
    "        'n_train': '\\# training',\n",
    "        'n_test': '\\# testing',\n",
    "        'n_features': '\\# features',\n",
    "        'n_samples': '\\# examples',\n",
    "        'n_classes': '\\# classes',\n",
    "    }\n",
    "    \n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    datasets = union_param_key(grid_param, \"dataset\")\n",
    "    if len(d.keys()) > 0:\n",
    "        first_key = list(d.keys())[0]\n",
    "        row_len = 1 if isinstance(d[first_key], str) else len(first_key)\n",
    "        col_len = 1 if isinstance(first_key, str) else len(first_key)\n",
    "        ori_cols = list(d.keys())\n",
    "    else:\n",
    "        row_len = 1\n",
    "        col_len = 1\n",
    "        ori_cols = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X, y, _ = auto_var.get_var_with_argument(\"dataset\", dataset)\n",
    "        row_name = (get_var_name(\"dataset\", dataset), )\n",
    "        for col in columns:\n",
    "            if col not in column_names:\n",
    "                continue\n",
    "            column_name = tuple(['-' for _ in range(col_len-1)] + [column_names[col]])\n",
    "            if col == \"n_features\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[1]\n",
    "            elif col == \"n_samples\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0]\n",
    "            elif col == \"n_train\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0] - 200\n",
    "            elif col == \"n_test\":\n",
    "                d.setdefault(column_name, {})[row_name] = 100\n",
    "            elif col == \"n_classes\":\n",
    "                d.setdefault(column_name, {})[row_name] = len(np.unique(y))\n",
    "                \n",
    "    for col in ori_cols:\n",
    "        d.move_to_end(col)\n",
    "        \n",
    "    return pd.DataFrame(d)\n",
    "    \n",
    "def cmp_ratio(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    cmp_base = []\n",
    "    \n",
    "    i = 0\n",
    "    for col, col_dict in d.items():\n",
    "        ret[col] = col_dict\n",
    "        if 'avg-pert' not in col[1]:\n",
    "            continue\n",
    "        if i == 0 or i == 1:\n",
    "            cmp_base.append(col_dict)\n",
    "            i += 1\n",
    "            continue\n",
    "        temp = {}\n",
    "        for k, v in col_dict.items():\n",
    "            if v == -1 or cmp_base[i % 2][k] == -1:\n",
    "                temp[k] = int(-1)\n",
    "            else:\n",
    "                v = v.replace(\"$\", \"\")\n",
    "                t = cmp_base[i % 2][k].replace(\"$\", \"\")\n",
    "                temp[k] = \"$%.2f$\" % (float(v) / float(t))\n",
    "        \n",
    "        ret[tuple([c for c in col[:-1]] + [\"%s imp.\" % col[-1]])] = temp\n",
    "        i += 1\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def max_imp(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    def add_new_col(col_list, ret):\n",
    "        new_col = {}\n",
    "        \n",
    "        for attack_name in [col_list[0][0][1], col_list[1][0][1]]:\n",
    "            temp = list(filter(lambda t: t[0][1] == attack_name, col_list))\n",
    "            imps = []\n",
    "            for c in temp:\n",
    "                imps.append([float(v.replace(\"$\", \"\")) if v != -1 else -1 for _, v in c[1].items()])\n",
    "            imps = (np.array(imps).T).argmax(axis=1)\n",
    "\n",
    "            new_col = {}\n",
    "            new_col_imp = {}\n",
    "            new_col_eps = {}\n",
    "            pcol = temp[0][0]\n",
    "            \n",
    "            if 'd' in pcol[0].split(\"-\")[-1]:\n",
    "                tt = pcol[0].split(\"-\")\n",
    "                tt.pop(-2)\n",
    "            else:\n",
    "                tt = pcol[0].split(\"-\")[:-1]\n",
    "            new_col_name = (\"-\".join(tt), pcol[1])\n",
    "            new_col_imp_name = (\"-\".join(tt), (\"%s imp.\" % pcol[1]))\n",
    "            new_col_eps_name = (\"-\".join(tt), (\"%s $\\\\epsilon$\" % pcol[1]))\n",
    "            for i, idx in enumerate(imps):\n",
    "                k, v = list(temp[idx][1].items())[i]\n",
    "                new_col[k] = v\n",
    "                k, v = list(temp[idx][2].items())[i]\n",
    "                new_col_imp[k] = v \n",
    "\n",
    "                if 'd' in temp[idx][0][0].split(\"-\")[-1]:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-2]) * 0.01))[1:]\n",
    "                else:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-1]) * 0.01))[1:]\n",
    "\n",
    "            ret[new_col_eps_name] = new_col_eps\n",
    "            ret[new_col_name] = new_col\n",
    "            ret[new_col_imp_name] = new_col_imp\n",
    "    \n",
    "    prev_col = None\n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if 'd' in col[0].split(\"-\")[-1]:\n",
    "            check_idx = -2\n",
    "        else:\n",
    "            check_idx = -1\n",
    "            \n",
    "        if i == 0 or i == 1:\n",
    "            ret[col] = col_dict\n",
    "            continue\n",
    "            \n",
    "        if len(temp) == 0:\n",
    "            temp.append(col_dict)\n",
    "        elif i % 2 == 1:\n",
    "            temp[-1] = (prev_col, temp[-1], col_dict)\n",
    "            if i == (len(d.items())-1):\n",
    "                add_new_col(temp, ret)\n",
    "        else:\n",
    "            if col[0].split(\"-\")[:check_idx] != prev_col[0].split(\"-\")[:check_idx]:\n",
    "                add_new_col(temp, ret)\n",
    "                temp = [col_dict]\n",
    "            else:\n",
    "                temp.append(col_dict)\n",
    "                \n",
    "        prev_col = col\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def bold_best(df, reverse=False):\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        temp.append([])\n",
    "        for row, row_value in col_dict.items():\n",
    "            if isinstance(row_value, str):\n",
    "                temp[-1].append(float(row_value.replace(\"$\", '')))\n",
    "            else:\n",
    "                temp[-1].append(np.inf if reverse else -np.inf)\n",
    "            \n",
    "    temp = np.array(temp).T\n",
    "    if reverse:\n",
    "        best_idx = temp.argmin(axis=1)\n",
    "    else:\n",
    "        best_idx = temp.argmax(axis=1)\n",
    "        \n",
    "    ret = OrderedDict()\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        ret[col] = {}\n",
    "        for j, (row, row_value) in enumerate(col_dict.items()):\n",
    "            if not isinstance(row_value, str):\n",
    "                ret[col][row] = row_value\n",
    "            else:\n",
    "                if float(row_value[1:-1]) == temp[j][best_idx[j]]:\n",
    "                    ret[col][row] = \"$\\\\mathbf{\" + row_value[1:-1] + \"}$\"\n",
    "                else:\n",
    "                    ret[col][row] = row_value\n",
    "\n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def gen_table(exp_name, grid_params, columns, rows, objs=None,\n",
    "              combine_method=None, additionals=None, obj_formats=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    df = pd.DataFrame({})\n",
    "    if combine_method is None:\n",
    "        df = avg_pert_table(exp_name, grid_params, columns, rows, objs, obj_formats)\n",
    "        if additionals:\n",
    "            for fn in additionals:\n",
    "                df = fn(df)\n",
    "    else:\n",
    "        dfs = []\n",
    "        for g in grid_params:\n",
    "            df = avg_pert_table(exp_name, g, columns, rows, objs, obj_formats)\n",
    "            if additionals:\n",
    "                for fn in additionals:\n",
    "                    df = fn(df)\n",
    "            dfs.append(df)\n",
    "        df = pd.concat(dfs, axis=combine_method)\n",
    "    \n",
    "    if 'dataset' in rows:\n",
    "        df = dataset_stat_column(df, grid_param, columns, rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(df, grid_param):\n",
    "    # col = ['model', 'attack']\n",
    "    ret = OrderedDict()\n",
    "    tst_df = params_to_dataframe(grid_param, ['tst_score'])\n",
    "\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    models = set([c[0] for c, _ in d.items()])\n",
    "    \n",
    "    prev_col =None\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        new_col_dict = OrderedDict({})\n",
    "        if i == 0:\n",
    "            for row, _ in col_dict.items():\n",
    "                temp_df = tst_df[(tst_df['model'] == col[0].replace(\"-\", \"_\"))\n",
    "                                 & (tst_df['attack'] == 'blackbox') \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        elif '\\\\epsilon' in col[1]:\n",
    "            m = re.match(r\"(?P<attack>[a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", col[1])\n",
    "            attack_name = m.group(\"attack\")[:-9].replace(\"-\", \"_\") # remove '$epsilon$'\n",
    "            for row, row_val in col_dict.items():\n",
    "                if 'd' in col[0].split('-')[-1]:\n",
    "                    model_name = '%s-%d-%s' % ('-'.join(col[0].split('-')[:-1]),\n",
    "                                               int(float(row_val.replace(\"$\", \"\"))*100),\n",
    "                                               col[0].split('-')[-1],)\n",
    "                else:\n",
    "                    model_name = \"%s-%d\" % (col[0], int(float(row_val.replace(\"$\", \"\"))*100))\n",
    "                model_name = model_name.replace(\"-\", \"_\")\n",
    "                temp_df = tst_df[(tst_df['model'] == model_name)\n",
    "                                 & (tst_df['attack'] == attack_name) \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert $\\\\epsilon$', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        prev_col = col\n",
    "        ret[col] = col_dict\n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "#params_to_dataframe(grid_param, ['trnX_len', 'aug_len']).groupby(['dataset', 'model'])['aug_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "#_, exp_name, grid_param, _ = dt_robustness()\n",
    "#_, exp_name, grid_param, _ = rf_robustness()\n",
    "#_, exp_name, grid_param, _ = nn_k3_robustness()\n",
    "#df = params_to_dataframe(grid_param, ['avg_pert', 'tst_score']).groupby(['dataset', 'model'])\n",
    "#df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\tiny\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.0pt}\n",
      "\\begin{tabular}{l|cccc|ccc|cccc|cccc}\n",
      "\\toprule\n",
      "        & \\multicolumn{4}{c}{1-NN} & \\multicolumn{3}{c}{3-NN} & \\multicolumn{4}{c}{DT} & \\multicolumn{4}{c}{RF} \\\\\n",
      "        & regular & AT & Wang's & AP & regular & AT & AP & regular & AT & RS & AP & regular & AT & RS & AP \\\\\n",
      "\\midrule\n",
      "australian &                $1.00$ &                $0.64$ &       $\\mathbf{1.65}$ &       $\\mathbf{1.65}$ &                          $1.00$ &                          $0.68$ &                 $\\mathbf{1.20}$ &                 $1.00$ &                  $2.36$ &            $\\mathbf{5.86}$ &                         $2.37$ &                     $1.00$ &                     $1.07$ &            $\\mathbf{1.12}$ &                     $1.04$ \\\\\n",
      "cancer &                $1.00$ &                $0.82$ &                $1.05$ &       $\\mathbf{1.41}$ &                          $1.00$ &                          $1.06$ &                 $\\mathbf{1.39}$ &                 $1.00$ &                  $0.85$ &                     $1.09$ &                $\\mathbf{1.19}$ &                     $1.00$ &                     $0.87$ &            $\\mathbf{1.54}$ &                     $1.26$ \\\\\n",
      "covtype &                $1.00$ &                $0.61$ &       $\\mathbf{3.17}$ &       $\\mathbf{3.17}$ &                          $1.00$ &                          $0.81$ &                 $\\mathbf{2.55}$ &                 $1.00$ &                  $1.07$ &                     $2.90$ &                $\\mathbf{4.84}$ &                     $1.00$ &                     $0.93$ &                     $1.59$ &            $\\mathbf{2.10}$ \\\\\n",
      "diabetes &                $1.00$ &                $0.83$ &       $\\mathbf{4.69}$ &       $\\mathbf{4.69}$ &                          $1.00$ &                          $0.87$ &                 $\\mathbf{2.97}$ &                 $1.00$ &                  $0.93$ &                     $1.53$ &                $\\mathbf{2.22}$ &                     $1.00$ &                     $1.19$ &                     $1.25$ &            $\\mathbf{2.22}$ \\\\\n",
      "f-mnist06 &                $1.00$ &                $0.94$ &                $2.09$ &       $\\mathbf{2.12}$ &                          $1.00$ &                          $0.86$ &                 $\\mathbf{1.47}$ &                 $1.00$ &                  $0.82$ &            $\\mathbf{3.91}$ &                         $1.85$ &                     $1.00$ &                     $0.97$ &                     $1.17$ &            $\\mathbf{1.81}$ \\\\\n",
      "f-mnist35 &                $1.00$ &                $0.80$ &                $1.02$ &       $\\mathbf{1.08}$ &                          $1.00$ &                          $0.77$ &                 $\\mathbf{1.05}$ &                 $1.00$ &                  $1.11$ &            $\\mathbf{2.64}$ &                         $2.07$ &                     $1.00$ &                     $0.90$ &                     $1.23$ &            $\\mathbf{1.32}$ \\\\\n",
      "fourclass &                $1.00$ &                $0.93$ &       $\\mathbf{3.09}$ &       $\\mathbf{3.09}$ &                          $1.00$ &                          $0.89$ &                 $\\mathbf{3.09}$ &                 $1.00$ &                  $1.06$ &                     $1.23$ &                $\\mathbf{3.04}$ &                     $1.00$ &                     $1.03$ &                     $1.93$ &            $\\mathbf{3.59}$ \\\\\n",
      "halfmoon &                $1.00$ &                $1.03$ &                $1.98$ &       $\\mathbf{2.73}$ &                          $1.00$ &                          $0.93$ &                 $\\mathbf{1.92}$ &                 $1.00$ &                  $1.54$ &                     $1.98$ &                $\\mathbf{2.58}$ &                     $1.00$ &                     $1.04$ &                     $1.01$ &            $\\mathbf{1.82}$ \\\\\n",
      "mnist17 &                $1.00$ &                $0.78$ &                $1.01$ &       $\\mathbf{1.20}$ &                          $1.00$ &                          $0.81$ &                 $\\mathbf{1.13}$ &                 $1.00$ &                  $1.14$ &            $\\mathbf{2.91}$ &                         $1.54$ &                     $1.00$ &                     $0.93$ &                     $1.11$ &            $\\mathbf{1.29}$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{\n",
      "The \\defenderscore across four nonparametric classifiers and corresponding competitors.\n",
      "A number greater than one indicates that the defense yields a more robust model, \n",
      "while less than one indicates less robustness (higher is better; best is in bold).\n",
      "}\n",
      "\\label{table:compare_defense_avg_pert}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def improvement(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        ret[col] = {}\n",
    "        for row, row_value in col_dict.items():\n",
    "            if i == 0:\n",
    "                ref = col_dict\n",
    "                value = 1.0\n",
    "            elif ref[row] == -1 or row_value == -1:\n",
    "                value = -1.\n",
    "            else:\n",
    "                value = (float(row_value.replace(\"$\", '')) / float(ref[row].replace(\"$\", '')))\n",
    "                \n",
    "            ret[col][row] = \"$%.2f$\" % value\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "_, exp_name, grid_param, _ = compare_defense()\n",
    "avg_caption = \"\"\"\n",
    "The \\defenderscore across four nonparametric classifiers and corresponding competitors.\n",
    "A number greater than one indicates that the defense yields a more robust model, \n",
    "while less than one indicates less robustness (higher is better; best is in bold).\n",
    "\"\"\"\n",
    "table_str = table_wrapper(gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[improvement, bold_best]\n",
    "            ), '%s_%s' % (exp_name, 'avg_pert'), caption=avg_caption)\n",
    "table_str = table_str.replace(\"                 knn1 &          adv-nn-k1-30 &     robustv2-nn-k1-30 &   advPruning-nn-k1-30\",\n",
    "                              \"\\multicolumn{4}{c}{1-NN}\")\n",
    "table_str = table_str.replace(\"                           knn3 &                    adv-nn-k3-30 &             advPruning-nn-k3-30\",\n",
    "                              \"\\multicolumn{3}{c}{3-NN}\")\n",
    "table_str = table_str.replace(\"      decision-tree-d5 & adv-decision-tree-d5-30 & robust-decision-tree-d5-30 & advPruning-decision-tree-d5-30\",\n",
    "                              \"\\multicolumn{4}{c}{DT}\")\n",
    "table_str = table_str.replace(\"      random-forest-100-d5 &           adv-rf-100-30-d5 &        robust-rf-100-30-d5 &    advPruning-rf-100-30-d5\",\n",
    "                              \"\\multicolumn{4}{c}{RF}\")\n",
    "table_str = table_str.replace(\" mlp &        adv-mlp-30 &  advPruning-mlp-30\",\n",
    "                              \"\\multicolumn{3}{c}{MLP}\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert\",\n",
    "                              \"regular & AT & Wang's & AP\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region-avg-pert & rev-nnopt-k3-50-region-avg-pert & rev-nnopt-k3-50-region-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\"dt-attack-opt-avg-pert &  dt-attack-opt-avg-pert &     dt-attack-opt-avg-pert &         dt-attack-opt-avg-pert\",\n",
    "                              \"regular & AT & RS & AP\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert\",\n",
    "                              \"regular & AT & RS & AP\")\n",
    "table_str = table_str.replace(\"pgd-avg-pert &      pgd-avg-pert &     pgd-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\"adv-nnopt-k1-all-avg-pert\", \"AT\")\n",
    "table_str = table_str.replace(\"advPruning-decision-tree-d5-30\", \"AP\")\n",
    "table_str = table_str.replace(\"llllllllllllllll\", \"l|cccc|ccc|cccc|cccc\")\n",
    "#for k, v in variable_name['dataset'].items():\n",
    "#    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "print(table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = parametric_defense()\n",
    "table_str = gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[improvement, bold_best]\n",
    "            ).to_latex(escape=False)\n",
    "table_str = table_str.replace(\"        sklr &  adv-sklr-30 & advPruning-sklr-30\",\n",
    "                              \"\\multicolumn{3}{c}{sklr}\")\n",
    "table_str = table_str.replace(\"logistic-regression & adv-logistic-regression-30 & advPruning-logistic-regression-30\",\n",
    "                              \"\\multicolumn{3}{c}{LR}\")\n",
    "table_str = table_str.replace(\"         mlp &        adv-mlp-30 & advPruning-mlp-30\",\n",
    "                              \"\\multicolumn{3}{c}{MLP}\")\n",
    "table_str = table_str.replace(\"pgd-avg-pert & pgd-avg-pert &     pgd-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\"       pgd-avg-pert &               pgd-avg-pert &                      pgd-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\" pgd-avg-pert &      pgd-avg-pert &      pgd-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "\n",
    "table_str = table_str.replace(\"lllllll\", \"l|ccc|ccc\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = compare_attacks()\n",
    "avg_caption = \"The Empirical robustness for different attack on four different classifier.\"\n",
    "table_str = table_wrapper(gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[partial(bold_best, reverse=True)]\n",
    "            ), '%s_%s' % (exp_name, 'avg_pert'), caption=avg_caption)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"llllllllllll\", \"l|ccc|ccc|ccc|cc\")\n",
    "table_str = table_str.replace(\"-avg-pert\", \"\")\n",
    "table_str = table_str.replace(\"direct-k1\", \"Direct\")\n",
    "table_str = table_str.replace(\"direct-k3\", \"Direct\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all\", \"RBA-Exact\")\n",
    "table_str = table_str.replace(\"dt-papernots\", \"Papernot's\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"RBA-Approx\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-100\", \"RBA-Approx\")\n",
    "table_str = table_str.replace(\"dt-attack-opt\", \"RBA-Exact\")\n",
    "table_str = table_str.replace(\"decision-tree-d5\", \"DT\")\n",
    "table_str = table_str.replace(\"random-forest-100-d5\", \"RF\")\n",
    "table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "table_str = table_str.replace(\"\\multicolumn{3}{l}\", \"\\multicolumn{3}{c}\")\n",
    "table_str = table_str.replace(\"\\multicolumn{2}{l}\", \"\\multicolumn{2}{c}\")\n",
    "table_str = table_str.replace(\"blackbox\", \"BBox\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fns = [nn_k1_robustness_figs, nn_k3_robustness_figs, dt_robustness_figs, rf_robustness_figs]\n",
    "model_names = [\"1-NN\", \"3-NN\", \"Decision tree\", \"Random forest\"]\n",
    "def get_label_name(name):\n",
    "    if 'advPruning' in name:\n",
    "        return \"AP\"\n",
    "    elif 'robust' in name:\n",
    "        return \"RS\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"Reg.\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_label_color(name):\n",
    "    if 'advPruning' in name:\n",
    "        return \"#ff7f0e\"\n",
    "    elif 'robust' in name:\n",
    "        return \"#1f77b4\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"#7f7f7f\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=False):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    \n",
    "    fig_paths = plot_result(df, exp_name, control, variables,\n",
    "                            get_title_fn=lambda g: g['dataset'],\n",
    "                            get_label_name_fn=get_label_name,\n",
    "                            get_label_color_fn=get_label_color,\n",
    "                            show_plot=show_plot)\n",
    "    return fig_paths\n",
    "\n",
    "def fig_paths_latex(fig_paths: List[List[Tuple[Dict, str]]], fig_label, caption):\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for row in fig_paths:\n",
    "        for entry in row:\n",
    "            g, img_path = entry\n",
    "            ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=%.2f\\\\textwidth]{%s}}\"\"\" % (g['subfig_label'], 1/len(fig_paths[0]), img_path)\n",
    "        ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, fig_label)\n",
    "    return ret\n",
    "\n",
    "fig_paths = []\n",
    "for i, fn in enumerate(exp_fns):\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    fig_path = compare_nn_plots(exp_name, grid_param, show_plot=False)\n",
    "    for g, _ in fig_path:\n",
    "        g['subfig_label'] = model_names[i]\n",
    "        for k, v in variable_name['dataset'].items():\n",
    "            g['subfig_label'] = re.sub(k, v, g['subfig_label'])\n",
    "    fig_paths.append(fig_path)\n",
    "transpose = [list() for c in fig_paths[0]]\n",
    "for i, col in enumerate(fig_paths):\n",
    "    for j, r in enumerate(col):\n",
    "        transpose[j].append(r)\n",
    "        \n",
    "caption = \"The maximum perturbation distance allowed versus accuracy.\"\n",
    "fig_str = fig_paths_latex(transpose[:5], \"defense-cmp\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp_fig.tex')\n",
    "\n",
    "fig_str = fig_paths_latex(transpose[5:], \"defense-cmp2\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp2_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = compare_nns()\n",
    "\n",
    "def get_title_fn(g):\n",
    "    ret = g['dataset']\n",
    "    for k, v in variable_name['dataset'].items():\n",
    "        ret = re.sub(k.replace('_', '-'), v, ret)\n",
    "    return ret\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    figs = plot_result(df, exp_name, control, variables, get_title_fn=get_title_fn, show_plot=show_plot)\n",
    "    fig_paths = []\n",
    "    for i, f in enumerate(figs):\n",
    "        if i % 3 == 0:\n",
    "            fig_paths.append([])\n",
    "        f[0]['subfig_label'] = f[0]['dataset']\n",
    "        for k, v in variable_name['dataset'].items():\n",
    "            f[0]['subfig_label'] = re.sub(k, v, f[0]['subfig_label'])\n",
    "        fig_paths[-1].append(f)\n",
    "    \n",
    "    return fig_paths_latex(fig_paths, exp_name, caption=caption)\n",
    "caption = \"\"\"\n",
    "The maximum perturbation distance allowed versus accuracy with different $k$ of $k$-NN classifier\n",
    "using RBA-Approx attack searching 50 regions.\"\n",
    "\"\"\"\n",
    "fig_str = compare_nn_plots(exp_name, grid_param, caption=caption, show_plot=False)\n",
    "write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import datasets, tree_datasets\n",
    "_, _, grid_param, _ = tst_scores()\n",
    "\n",
    "col_names = [\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# training \\\\\\\\ (1-NN, 3-NN)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# training \\\\\\\\ (DT, RF, MLP)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# testing \\\\\\\\ (perturbation)}\",\n",
    "    \"\\\\parbox{15mm}{\\\\centering \\# testing \\\\\\\\ (test accuracy)}\",\n",
    "    \"\\# features\",\n",
    "    \"\\# classes\",\n",
    "]\n",
    "ret = OrderedDict()\n",
    "for i, ds in enumerate(datasets):\n",
    "    X, y, _ = auto_var.get_var_with_argument(\"dataset\", ds)\n",
    "    tX, _, _ = auto_var.get_var_with_argument(\"dataset\", tree_datasets[i])\n",
    "    ret[auto_var.get_var_shown_name(\"dataset\", ds)] = OrderedDict([\n",
    "        (col_names[0], X.shape[0]-200),\n",
    "        (col_names[1], tX.shape[0]-200),\n",
    "        (col_names[2], 100),\n",
    "        (col_names[3], 200),\n",
    "        (col_names[4], X.shape[1]),\n",
    "        (col_names[5], 2),\n",
    "    ])\n",
    "df = pd.DataFrame(ret).T\n",
    "df = df[[c for c in col_names]]\n",
    "\n",
    "exp_name = \"dataset-stats\"\n",
    "caption = \"Dataset statistics.\"\n",
    "table_str = table_wrapper(df, table_name=exp_name, caption=caption)\n",
    "table_str = table_str.replace(\"lrrrrrr\", \"lcccccc\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_fonts(series):\n",
    "    if '\\\\# train' in series.name[1]:\n",
    "        return series.apply(lambda x: \"$%d$\" % x if not np.isnan(x) else \"-1\")\n",
    "    else:\n",
    "        return series.apply(lambda x: (\"$%.3f$\" % x) if x >= 1 else (\"$%.3f$\" % x).replace(\"0.\", \".\"))\n",
    "    \n",
    "def preprocess(grid_param):\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attacks = []\n",
    "    for i in union_param_key(grid_param, 'attack'):\n",
    "        for s in ['-avg-pert', '-tst-score', '-aug-len', '-imp']:\n",
    "            attacks.append(i.replace(\"_\", \"-\") + s)\n",
    "    col_names = []\n",
    "    for model in models:\n",
    "        for attack in attacks:\n",
    "            if '-imp' in attack and model == models[0]:\n",
    "                continue\n",
    "            col_names.append((model, attack))\n",
    "    return col_names\n",
    "\n",
    "def process(task_fn):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "                   combine_method=1, objs=['tst_score', 'avg_pert', 'aug_len'],\n",
    "                   additionals=[])\n",
    "\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attack = grid_param[0]['attack'][0].replace(\"_\", '-')\n",
    "    col_names = preprocess(grid_param)\n",
    "\n",
    "    df = df.apply(lambda a: a.apply(lambda b: float(str(b).replace(\"$\", \"\")) if b else b))\n",
    "    for model in models[1:]:\n",
    "        df[(model, attack + '-imp')] = df[(model, attack + '-avg-pert')] / df[(models[0], attack + '-avg-pert')]\n",
    "    df = df[col_names]\n",
    "    df = df.rename(index=str, columns={\n",
    "        attack + \"-aug-len\": \"\\# train\",\n",
    "        attack + \"-tst-score\": parbox(8, \"testing \\\\\\\\ accuracy\"),\n",
    "        attack + \"-avg-pert\": parbox(9, \"empirical \\\\\\\\ robustness\"),\n",
    "        attack + \"-imp\": \"\\\\defenderscore\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def postprocess(task_fn, df, rename_columns, caption):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = df.rename(index=str, columns=rename_columns)\n",
    "    df = df.apply(structure_fonts)\n",
    "    table_str = table_wrapper(df, table_name=exp_name, caption=caption,)\n",
    "    table_str = table_str.replace(\"{l}\", \"{c}\")\n",
    "    table_str = table_str.replace(\"llllllllllllllll\", \"lccc|cccc|cccc|cccc\")\n",
    "    table_str = table_str.replace(\"$.000$\", \"-\")\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = nn_k1_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for 1-NN.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"knn1\": \"1-NN\",\n",
    "    \"advPruning-nn-k1-50\": \"AP (separation parameter $r$=.5)\",\n",
    "    \"advPruning-nn-k1-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-nn-k1-10\": \"AP (separation parameter $r$=.1)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = nn_k3_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for 3-NN.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"knn3\": \"3-NN\",\n",
    "    \"advPruning-nn-k3-50\": \"AP (separation parameter $r$=.5)\",\n",
    "    \"advPruning-nn-k3-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-nn-k3-10\": \"AP (separation parameter $r$=.1)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = dt_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for DT.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"decision-tree-d5\": \"DT\",\n",
    "    \"advPruning-decision-tree-d5-50\": \"AP (separation parameter $r$=.5)\",\n",
    "    \"advPruning-decision-tree-d5-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-decision-tree-d5-10\": \"AP (separation parameter $r$=.1)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = rf_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for RF.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"random-forest-100-d5\": \"RF\",\n",
    "    \"advPruning-rf-100-10-d5\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-rf-100-30-d5\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-rf-100-50-d5\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = lr_ap_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for LR.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"advPruning-mlp-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-mlp-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-mlp-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = mlp_ap_robustness\n",
    "df = process(fn)\n",
    "caption = \"\"\"\n",
    "The number of training data left after AP, testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen separation parameter of AP for MLP.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"advPruning-logistic-regression-10\": \"AP (separation parameter $r$=.1)\",\n",
    "    \"advPruning-logistic-regression-30\": \"AP (separation parameter $r$=.3)\",\n",
    "    \"advPruning-logistic-regression-50\": \"AP (separation parameter $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2(task_fn):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "                   combine_method=1, objs=['tst_score', 'avg_pert'], additionals=[])\n",
    "\n",
    "    models = [i.replace(\"_\", \"-\") for i in union_param_key(grid_param, 'model')]\n",
    "    attack = grid_param[0]['attack'][0].replace(\"_\", '-')\n",
    "    col_names = [a for a in preprocess(grid_param) if '-aug-len' not in a[1]]\n",
    "\n",
    "    df = df.apply(lambda a: a.apply(lambda b: float(str(b).replace(\"$\", \"\")) if b else b))\n",
    "    for model in models[1:]:\n",
    "        df[(model, attack + '-imp')] = df[(model, attack + '-avg-pert')] / df[(models[0], attack + '-avg-pert')]\n",
    "    df = df[col_names]\n",
    "    df = df.rename(index=str, columns={\n",
    "        attack + \"-tst-score\": parbox(8, \"testing \\\\\\\\ accuracy\"),\n",
    "        attack + \"-avg-pert\": parbox(9, \"empirical \\\\\\\\ robustness\"),\n",
    "        attack + \"-imp\": \"\\\\defenderscore\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def postprocess2(task_fn, df, rename_columns, caption):\n",
    "    _, exp_name, grid_param, _ = task_fn()\n",
    "    df = df.rename(index=str, columns=rename_columns)\n",
    "    df = df.apply(structure_fonts)\n",
    "    table_str = table_wrapper(df, table_name=exp_name, caption=caption,)\n",
    "    table_str = table_str.replace(\"{l}\", \"{c}\")\n",
    "    table_str = table_str.replace(\"llllllllllll\", \"lcc|ccc|ccc|ccc\")\n",
    "    table_str = table_str.replace(\"$.000$\", \"-\")\n",
    "    return table_str\n",
    "\n",
    "fn = mlp_at_robustness\n",
    "df = process2(fn)\n",
    "caption = \"\"\"\n",
    "The testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen attack distance of AT for MLP.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"adv-mlp-10\": \"AT (attack distance $r$=.1)\",\n",
    "    \"adv-mlp-30\": \"AT (attack distance $r$=.3)\",\n",
    "    \"adv-mlp-50\": \"AT (attack distance $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')\n",
    "\n",
    "fn = lr_at_robustness\n",
    "df = process2(fn)\n",
    "caption = \"\"\"\n",
    "The testing accuracy, empirical robustness,\n",
    "and \\\\defenderscore with differen attack distance of AT for LR.\n",
    "\"\"\"\n",
    "rename_columns = {\n",
    "    \"logistic-regression\": \"LR\",\n",
    "    \"adv-logistic-regression-10\": \"AT (attack distance $r$=.1)\",\n",
    "    \"adv-logistic-regression-30\": \"AT (attack distance $r$=.3)\",\n",
    "    \"adv-logistic-regression-50\": \"AT (attack distance $r$=.5)\",\n",
    "}\n",
    "_, exp_name, _, _ = fn()\n",
    "table_str = postprocess2(fn, df, rename_columns, caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash ./sync_report.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-788ee363e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = tst_scores()\n",
    "avg_caption = \"test accuracy with different defense strength\"\n",
    "df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "               combine_method=1, objs=['tst_score'], additionals=[])\n",
    "table_str = table_wrapper(df, table_name=exp_name, caption=avg_caption,)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lllllllllllllllll\", \"lcccc|cccc|cccc|cccc\")\n",
    "table_str = table_str.replace(\"                  knn1 &      advPruning-nn-k1-10 &      advPruning-nn-k1-30 &      advPruning-nn-k1-50\",\n",
    "                              \"\\multicolumn{4}{c}{1-NN}\")\n",
    "table_str = table_str.replace(\"                            knn3 &                advPruning-nn-k3-10 &                advPruning-nn-k3-30 &                advPruning-nn-k3-50\",\n",
    "                              \"\\multicolumn{4}{c}{3-NN}\")\n",
    "table_str = table_str.replace(\"       decision-tree-d5 & advPruning-decision-tree-d5-10 & advPruning-decision-tree-d5-30 & advPruning-decision-tree-d5-50\",\n",
    "                              \"\\multicolumn{4}{c}{DT}\")\n",
    "table_str = table_str.replace(\"       random-forest-100-d5 &       advPruning-rf-100-10-d5 &       advPruning-rf-100-30-d5 &       advPruning-rf-100-50-d5\",\n",
    "                              \"\\multicolumn{4}{c}{RF}\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all-tst-score & \" * 4,\n",
    "                              \"Regular & AP-10 & AP-30 & AP-50 & \")\n",
    "table_str = table_str.replace(\"& rev-nnopt-k3-50-region-tst-score \" * 4,\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "table_str = table_str.replace(\"& dt-attack-opt-tst-score &      dt-attack-opt-tst-score &      dt-attack-opt-tst-score &      dt-attack-opt-tst-score\",\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "table_str = table_str.replace(\"& rf-attack-rev-100-tst-score \" * 4,\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_robustness()\n",
    "avg_caption = \"Random forest average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"random-forest-100-d5\", \"random forest\")\n",
    "table_str = table_str.replace(\"robust-rf-100-d5\", \"random forest with robust splitting\")\n",
    "table_str = table_str.replace(\"advPruning-rf-100-d5\", \"random forest with adversarial pruning\")\n",
    "\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = dt_robustness()\n",
    "avg_caption = \"Decision tree average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"llllllllllllllllllllllllllll\", \"llll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"dt-attack-opt\", \"opt\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_k1_optimality_figs()\n",
    "df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "datasets = union_param_key(grid_param, 'dataset')\n",
    "for dataset in datasets:\n",
    "    temp_df = df[(df['dataset'] == dataset)]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(dataset)\n",
    "    x = []\n",
    "    for k, v in temp_df.groupby(\"attack\"):\n",
    "        avg_pert = v['avg_pert'].mean()\n",
    "        if k == 'blackbox':\n",
    "            bb_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='Cheng', colors='c')\n",
    "        elif k.split('_')[-1] == 'all':\n",
    "            opt_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='opt')\n",
    "        elif k.split('_')[-1] == 'rev':\n",
    "            x.append((100, avg_pert))\n",
    "        else:\n",
    "            if k.split('_')[-1] != 'region':\n",
    "                x.append((int(k.split('_')[-1]), avg_pert))\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "    x = sorted(x, key=lambda t: t[0])\n",
    "    x, y = zip(*x)\n",
    "    ax.plot(x, y)\n",
    "    set_plot(fig, ax)\n",
    "    ax.set_ylim(opt_avg-0.03, max(list(y) + [bb_avg])+0.03)\n",
    "    ax.set_xlim(0, 100)\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in [nn_k1_robustness_figs, nn_k3_robustness_figs]:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "    datasets = union_param_key(grid_param, 'dataset')\n",
    "    for dataset in datasets:\n",
    "        temp_df = df[(df['dataset'] == dataset)]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(dataset)\n",
    "        x = []\n",
    "        for k, v in temp_df.groupby(\"attack\"):\n",
    "            avg_pert = v['avg_pert'].mean()\n",
    "            if k == 'blackbox':\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='Cheng')\n",
    "            elif k.split('_')[-1] == 'all':\n",
    "                opt_pert = avg_pert\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='opt')\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "        x = sorted(x, key=lambda t: t[0])\n",
    "        x, y = zip(*x)\n",
    "        ax.plot(x, y)\n",
    "        set_plot(fig, ax)\n",
    "        ax.set_ylim(opt_pert-0.03, max(y)+0.03)\n",
    "        ax.set_xlim(0, 50)\n",
    "        #ax.set_xscale('log')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_optimality()\n",
    "avg_caption = \"RF average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_optimality()\n",
    "avg_caption = \"3NN average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"nnopt-k3-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [rf_attack, opt_of_rf_attack, robust_rf]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    #columns = ['blackbox', 'rf_attack_rev_20', 'rf_attack_rev_100']\n",
    "    table_str = table_wrapper(exp_name, grid_param, ['attack'], ['dataset'], caption=avg_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(grid_param)\n",
    "    variables = grid_param[0]['attack']\n",
    "    #variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    #print(table_str)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnattack.models.robust_nn.eps_separation import build_collision_graph, find_min_cover\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=3)\n",
    "\n",
    "def gen_removed_figs(ds_name, eps):\n",
    "    fig_dir = \"./figs/removed/%s\" % ds_name \n",
    "    mkdir_p(fig_dir)\n",
    "    auto_var.set_variable_value(\"random_seed\", 0)\n",
    "    np.random.seed(0)\n",
    "    X, y, _ = auto_var.get_var_with_argument(\"dataset\", ds_name)\n",
    "    pts = PCA().fit_transform(X)\n",
    "    idx = np.arange(len(X))\n",
    "    np.random.shuffle(idx)\n",
    "    pts = MinMaxScaler().fit_transform(pts)\n",
    "\n",
    "    nn.fit(pts)\n",
    "    y_pts = [1 if i>0 else -1 for i in y]\n",
    "    adj_lst, graph = build_collision_graph(eps/2, pts, y_pts, np.inf)\n",
    "    matching, min_cover = find_min_cover(graph, adj_lst, y_pts)\n",
    "    \n",
    "    for i in min_cover:\n",
    "        _, idx = nn.kneighbors([pts[i]])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X[i].reshape(28, 28))\n",
    "        plt.savefig(f'{fig_dir}/{i}.eps', format='eps')\n",
    "        plt.close()\n",
    "        mkdir_p(f'{fig_dir}/{i}')\n",
    "        for j in idx[0]:\n",
    "            plt.imshow(X[j].reshape(28, 28))\n",
    "            plt.savefig(f'{fig_dir}/{i}/{j}.eps', format='eps')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_removed_figs('mnist17_2200', 0.3)\n",
    "gen_removed_figs('fashion_mnist35_2200', 0.3)\n",
    "gen_removed_figs('fashion_mnist06_2200', 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
