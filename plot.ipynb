{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from functools import reduce, partial\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Tuple, Union, Callable\n",
    "import pprint\n",
    "from mkdir_p import mkdir_p\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from nnattack.variables import auto_var\n",
    "from params import (\n",
    "    compare_attacks,\n",
    "    compare_defense,\n",
    "    \n",
    "    compare_nns,\n",
    "    nn_k1_robustness,\n",
    "    nn_k3_robustness,\n",
    "    \n",
    "    rf_robustness,\n",
    "    dt_robustness,\n",
    "    tst_scores,\n",
    "    \n",
    "    dt_robustness_figs,\n",
    "    nn_k1_robustness_figs,\n",
    "    nn_k3_robustness_figs,\n",
    "    rf_robustness_figs,\n",
    "    rf_optimality_figs,\n",
    "    nn_k1_optimality_figs,\n",
    "    nn_k3_optimality_figs,\n",
    ")\n",
    "from utils import set_plot, get_result, write_to_tex, union_param_key, params_to_dataframe\n",
    "\n",
    "auto_var.set_variable_value('random_seed', 0)\n",
    "auto_var.set_variable_value('ord', 'inf')\n",
    "auto_var.set_logging_level(0)\n",
    "\n",
    "compare_attacks = compare_attacks()\n",
    "compare_defense = compare_defense()\n",
    "tst_scores = tst_scores()\n",
    "\n",
    "compare_nns = compare_nns()\n",
    "nn_k1_robustness = nn_k1_robustness()\n",
    "nn_k3_robustness = nn_k3_robustness()\n",
    "rf_robustness = rf_robustness()\n",
    "dt_robustness = dt_robustness()\n",
    "dt_robustness_figs = dt_robustness_figs()\n",
    "nn_k1_robustness_figs = nn_k1_robustness_figs()\n",
    "nn_k3_robustness_figs = nn_k3_robustness_figs()\n",
    "rf_optimality_figs = rf_optimality_figs()\n",
    "nn_k1_optimality_figs = nn_k1_optimality_figs()\n",
    "nn_k3_optimality_figs = nn_k3_optimality_figs()\n",
    "rf_robustness_figs = rf_robustness_figs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_latex_figs(exp_name, control_var, caption):\n",
    "    control = ParameterGrid(control_var)\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for i, g in enumerate(control):\n",
    "        dataset, ord = g['dataset'], g['ord']\n",
    "        img_path = f'./figs/{exp_name}_{dataset}_{ord}.eps'\n",
    "        dataset = dataset.replace(\"_\", \" \")\n",
    "        ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=.45\\\\textwidth]{%s}}\"\"\" % (dataset, img_path)\n",
    "        if i % 2 == 1:\n",
    "            ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, exp_name)\n",
    "    return ret\n",
    "                      \n",
    "def plot_result(df, exp_name, control_var, variables,\n",
    "                get_title_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_name_fn: Union[Callable[[Dict], str], None]=None,\n",
    "                get_label_color_fn: Union[Callable[[Dict], str], None]=None, show_plot=True):\n",
    "    ret = []\n",
    "    for g in ParameterGrid(control_var):\n",
    "        temp_df = df\n",
    "                      \n",
    "        if get_title_fn is None:\n",
    "            title = exp_name\n",
    "            for k, v in g.items():\n",
    "                if v in variable_name[k]:\n",
    "                    title = title + f\"_{variable_name[k][v]}\"\n",
    "                else:\n",
    "                    title = title + f\"_{v}\"\n",
    "        else:\n",
    "            title = get_title_fn(g)\n",
    "            \n",
    "        for k, v in g.items():\n",
    "            temp_df = temp_df.loc[df[k] == v]\n",
    "                      \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(title)\n",
    "        for name, group in temp_df.groupby(variables):\n",
    "            #print(name, len(group))\n",
    "            eps_list = [re.findall(r'[-+]?\\d*\\.\\d+|\\d+', t)[0] for t in group.mean().index.tolist()[:-1]]\n",
    "            s = [r for r in group.mean().tolist()[:-1] if not np.isnan(r)]\n",
    "            x = [float(eps_list[i]) for i, r in enumerate(group.mean().tolist()[:-1]) if not np.isnan(r)]\n",
    "                      \n",
    "            if get_label_name_fn is not None:\n",
    "                label = get_label_name(name)\n",
    "            elif isinstance(name, str):\n",
    "                if variables[0] not in variable_name:\n",
    "                    label = name\n",
    "                elif name in variable_name[variables[0]]:\n",
    "                    label = variable_name[variables[0]][name]\n",
    "                else:\n",
    "                    label = name\n",
    "            else:\n",
    "                mod_names = []\n",
    "                for i, n in enumerate(name):\n",
    "                    if n in variable_name[variables[i]]:\n",
    "                        mod_names.append(variable_name[variables[i]][n])\n",
    "                    else:\n",
    "                        mod_names.append(n)\n",
    "                label = mod_name.join(\"_\")\n",
    "\n",
    "            if get_label_color_fn is not None:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5, color=get_label_color_fn(name))\n",
    "            else:\n",
    "                ax.plot(x, s, label=label, linewidth=3.5)\n",
    "\n",
    "        dataset = g['dataset']\n",
    "        ord = g['ord']\n",
    "        set_plot(fig, ax)\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        ret.append((g, f'./figs/{exp_name}_{dataset}_{ord}.eps'))\n",
    "        if show_plot:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    return ret\n",
    "                      \n",
    "variable_name = {\n",
    "    #'model': {\n",
    "    #    ''\n",
    "    #},\n",
    "    'dataset': {\n",
    "        r\"fashion_mnist35_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'f-mnist35',\n",
    "        r\"fashion_mnist06_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'f-mnist06',\n",
    "        r\"mnist17_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'mnist17',\n",
    "        r\"mnist35_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'mnist35',\n",
    "        r\"digits(?P<dims>_\\d+)?\": 'digits',\n",
    "        r\"halfmoon_(?P<samples>\\d+)\": 'halfmoon',\n",
    "        r\"ijcnn1_(?P<samples>\\d+)\": 'ijcnn',\n",
    "        r'covtypebin_(?P<samples>\\d+)': 'covtype',\n",
    "        \n",
    "        'abalone': 'abalone',\n",
    "        'iris': 'iris',\n",
    "        'wine': 'wine',\n",
    "        'covtype_3200': 'covtype',\n",
    "    },\n",
    "    'attack': {\n",
    "        'blackbox': 'Cheng\\'s',\n",
    "        'kernelsub_c10000_pgd': 'kernelsub',\n",
    "        'kernelsub_c1000_pgd': 'kernelsub',\n",
    "        'rev_nnopt_k1_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k1_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k1_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k1_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k3_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k3_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k3_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k3_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k5_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k5_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k5_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k5_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k7_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k7_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k7_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k7_50_region': 'nnopt-50',\n",
    "        \n",
    "        'nnopt_k1_all': 'nnopt-all',\n",
    "        'nnopt_k3_all': 'nnopt-all',\n",
    "        \n",
    "        'direct_k1': 'direct attack',\n",
    "        'direct_k3': 'direct attack',\n",
    "        'direct_k5': 'direct attack',\n",
    "        'direct_k7': 'direct attack',\n",
    "        \n",
    "        'rf_attack_all': 'RF-all',\n",
    "        'rf_attack_rev': 'RF-rev',\n",
    "        'rf_attack_rev_20': 'RF-rev-20',\n",
    "        'rf_attack_rev_50': 'RF-rev-50',\n",
    "        'rf_attack_rev_100': 'RF-rev-100',\n",
    "    },\n",
    "    'ord': {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_attack_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['attack']\n",
    "    plot_result(df, exp_name, control, variables, show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "    \n",
    "def get_var_name(var, arg):\n",
    "    if var == 'model':\n",
    "        if 'adv' in arg or 'robust' in arg:\n",
    "            arg = \"%s_%02d\" % (\"_\".join(arg.split(\"_\")[:-1]), int(arg.split(\"_\")[-1]))\n",
    "        else:\n",
    "            arg = arg\n",
    "    else:\n",
    "        arg = variable_name[var].get(arg, arg)\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def get_var_name(var, arg):\n",
    "    \n",
    "    if var == 'dataset':\n",
    "        for k, v in variable_name['dataset'].items():\n",
    "            arg = re.sub(k, v, arg)\n",
    "        return arg\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def avg_pert_table(exp_name, grid_param, columns, rows, objs:list=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    columns = list(filter(lambda a: a not in ['n_features', 'n_samples', 'n_classes'], columns))\n",
    "    if len(columns) == 0 or len(rows) == 0:\n",
    "        return pd.DataFrame({})\n",
    "    df = params_to_dataframe(grid_param, objs)\n",
    "    \n",
    "    d = OrderedDict()\n",
    "    col_grid = OrderedDict([(c, union_param_key(grid_param, c)) for c in columns])\n",
    "    row_grid = OrderedDict([(r, union_param_key(grid_param, r)) for r in rows])\n",
    "    for obj in objs:\n",
    "        temp_df = df.groupby(columns + rows)[obj].mean()\n",
    "        temp_df_sem = df.groupby(columns + rows)[obj].sem()\n",
    "        \n",
    "        if obj == 'tst_score':\n",
    "            assert columns[0] == 'model'\n",
    "        for col in ParameterGrid(col_grid):\n",
    "            col_k = tuple(col[c] for c in columns)\n",
    "            col_name = tuple([get_var_name(c, col[c]) for c in columns[:-1]] \\\n",
    "                             + [\"%s-%s\" % (get_var_name(columns[-1], col[columns[-1]]), obj.replace(\"_\", \"-\"))])\n",
    "            d[col_name] = {}\n",
    "            for row in ParameterGrid(row_grid):\n",
    "                row_k = tuple(row[r] for r in rows)\n",
    "                row_name = tuple(get_var_name(r, row[r]) for r in rows)\n",
    "                if (col_k + row_k) in temp_df:\n",
    "                    #d[col_name][row_name] = \"$%.3f \\pm %.3f$\" % (temp_df[col_k + row_k], temp_df_sem[col_k + row_k])\n",
    "                    d[col_name][row_name] = \"$%.3f$\" % (temp_df[col_k + row_k])\n",
    "                    d[col_name][row_name] = d[col_name][row_name].replace(\"0.\", \".\")\n",
    "                else:\n",
    "                    d[col_name][row_name] = -1\n",
    "\n",
    "    #d = OrderedDict([(k, d[k]) for k in d.keys()])\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def dataset_stat_column(df, grid_param, columns, rows):\n",
    "    if (\"n_features\" not in columns) and (\"n_samples\" not in columns) and (\"n_classes\" not in columns):\n",
    "        return df\n",
    "    \n",
    "    column_names = {\n",
    "        'n_features': '\\# features',\n",
    "        'n_samples': '\\# examples',\n",
    "        'n_classes': '\\# classes',\n",
    "    }\n",
    "    \n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    datasets = union_param_key(grid_param, \"dataset\")\n",
    "    if len(d.keys()) > 0:\n",
    "        first_key = list(d.keys())[0]\n",
    "        row_len = 1 if isinstance(d[first_key], str) else len(first_key)\n",
    "        col_len = 1 if isinstance(first_key, str) else len(first_key)\n",
    "        ori_cols = list(d.keys())\n",
    "    else:\n",
    "        row_len = 1\n",
    "        col_len = 1\n",
    "        ori_cols = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X, y, _ = auto_var.get_var_with_argument(\"dataset\", dataset)\n",
    "        row_name = (get_var_name(\"dataset\", dataset), )\n",
    "        for col in columns:\n",
    "            if col not in column_names:\n",
    "                continue\n",
    "            column_name = tuple(['-' for _ in range(col_len-1)] + [column_names[col]])\n",
    "            if col == \"n_features\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[1]\n",
    "            elif col == \"n_samples\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0]\n",
    "            elif col == \"n_classes\":\n",
    "                d.setdefault(column_name, {})[row_name] = len(np.unique(y))\n",
    "                \n",
    "    for col in ori_cols:\n",
    "        d.move_to_end(col)\n",
    "        \n",
    "    return pd.DataFrame(d)\n",
    "    \n",
    "def cmp_ratio(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    cmp_base = []\n",
    "    \n",
    "    i = 0\n",
    "    for col, col_dict in d.items():\n",
    "        ret[col] = col_dict\n",
    "        if 'avg-pert' not in col[1]:\n",
    "            continue\n",
    "        if i == 0 or i == 1:\n",
    "            cmp_base.append(col_dict)\n",
    "            i += 1\n",
    "            continue\n",
    "        temp = {}\n",
    "        for k, v in col_dict.items():\n",
    "            if v == -1 or cmp_base[i % 2][k] == -1:\n",
    "                temp[k] = int(-1)\n",
    "            else:\n",
    "                v = v.replace(\"$\", \"\")\n",
    "                t = cmp_base[i % 2][k].replace(\"$\", \"\")\n",
    "                temp[k] = \"$%.2f$\" % (float(v) / float(t))\n",
    "        \n",
    "        ret[tuple([c for c in col[:-1]] + [\"%s imp.\" % col[-1]])] = temp\n",
    "        i += 1\n",
    "        #ret[tuple([c for c in col[:-1]] + [\"%d imp.\" % i])] = temp\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def max_imp(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    def add_new_col(col_list, ret):\n",
    "        new_col = {}\n",
    "        \n",
    "        for attack_name in [col_list[0][0][1], col_list[1][0][1]]:\n",
    "            temp = list(filter(lambda t: t[0][1] == attack_name, col_list))\n",
    "            imps = []\n",
    "            for c in temp:\n",
    "                imps.append([float(v.replace(\"$\", \"\")) if v != -1 else -1 for _, v in c[1].items()])\n",
    "            imps = (np.array(imps).T).argmax(axis=1)\n",
    "\n",
    "            new_col = {}\n",
    "            new_col_imp = {}\n",
    "            new_col_eps = {}\n",
    "            pcol = temp[0][0]\n",
    "            \n",
    "            if 'd' in pcol[0].split(\"-\")[-1]:\n",
    "                tt = pcol[0].split(\"-\")\n",
    "                tt.pop(-2)\n",
    "            else:\n",
    "                tt = pcol[0].split(\"-\")[:-1]\n",
    "            new_col_name = (\"-\".join(tt), pcol[1])\n",
    "            new_col_imp_name = (\"-\".join(tt), (\"%s imp.\" % pcol[1]))\n",
    "            new_col_eps_name = (\"-\".join(tt), (\"%s $\\\\epsilon$\" % pcol[1]))\n",
    "            for i, idx in enumerate(imps):\n",
    "                k, v = list(temp[idx][1].items())[i]\n",
    "                new_col[k] = v\n",
    "                k, v = list(temp[idx][2].items())[i]\n",
    "                new_col_imp[k] = v \n",
    "\n",
    "                if 'd' in temp[idx][0][0].split(\"-\")[-1]:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-2]) * 0.01))[1:]\n",
    "                else:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-1]) * 0.01))[1:]\n",
    "\n",
    "            ret[new_col_eps_name] = new_col_eps\n",
    "            ret[new_col_name] = new_col\n",
    "            ret[new_col_imp_name] = new_col_imp\n",
    "    \n",
    "    prev_col = None\n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if 'd' in col[0].split(\"-\")[-1]:\n",
    "            check_idx = -2\n",
    "        else:\n",
    "            check_idx = -1\n",
    "            \n",
    "        if i == 0 or i == 1:\n",
    "            ret[col] = col_dict\n",
    "            continue\n",
    "            \n",
    "        if len(temp) == 0:\n",
    "            temp.append(col_dict)\n",
    "        elif i % 2 == 1:\n",
    "            temp[-1] = (prev_col, temp[-1], col_dict)\n",
    "            if i == (len(d.items())-1):\n",
    "                add_new_col(temp, ret)\n",
    "        else:\n",
    "            if col[0].split(\"-\")[:check_idx] != prev_col[0].split(\"-\")[:check_idx]:\n",
    "                add_new_col(temp, ret)\n",
    "                temp = [col_dict]\n",
    "            else:\n",
    "                temp.append(col_dict)\n",
    "                \n",
    "        prev_col = col\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def bold_best(df, reverse=False):\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        temp.append([])\n",
    "        for row, row_value in col_dict.items():\n",
    "            if isinstance(row_value, str):\n",
    "                temp[-1].append(float(row_value.replace(\"$\", '')))\n",
    "            else:\n",
    "                temp[-1].append(np.inf if reverse else -np.inf)\n",
    "            \n",
    "    temp = np.array(temp).T\n",
    "    if reverse:\n",
    "        best_idx = temp.argmin(axis=1)\n",
    "    else:\n",
    "        best_idx = temp.argmax(axis=1)\n",
    "        \n",
    "    ret = OrderedDict()\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        ret[col] = {}\n",
    "        for j, (row, row_value) in enumerate(col_dict.items()):\n",
    "            if not isinstance(row_value, str):\n",
    "                ret[col][row] = row_value\n",
    "            else:\n",
    "                if float(row_value[1:-1]) == temp[j][best_idx[j]]:\n",
    "                    ret[col][row] = \"$\\\\mathbf{\" + row_value[1:-1] + \"}$\"\n",
    "                else:\n",
    "                    ret[col][row] = row_value\n",
    "            \n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def gen_table(exp_name, grid_params, columns, rows, objs=None,\n",
    "              combine_method=None, additionals=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    df = pd.DataFrame({})\n",
    "    if combine_method is None:\n",
    "        df = avg_pert_table(exp_name, grid_params, columns, rows, objs)\n",
    "        if additionals:\n",
    "            for fn in additionals:\n",
    "                df = fn(df)\n",
    "    else:\n",
    "        dfs = []\n",
    "        for g in grid_params:\n",
    "            df = avg_pert_table(exp_name, g, columns, rows, objs)\n",
    "            if additionals:\n",
    "                for fn in additionals:\n",
    "                    df = fn(df)\n",
    "            dfs.append(df)\n",
    "        df = pd.concat(dfs, axis=combine_method)\n",
    "    \n",
    "    if 'dataset' in rows:\n",
    "        df = dataset_stat_column(df, grid_param, columns, rows)\n",
    "    return df\n",
    "\n",
    "def table_wrapper(table_df, table_name, caption=''):\n",
    "    t = \"\"\"\n",
    "\\\\begin{table}[h!]\n",
    "\\\\tiny\n",
    "\\\\centering\n",
    "\\\\setlength{\\\\tabcolsep}{2.0pt}\n",
    "\"\"\"\n",
    "    t += table_df.to_latex(escape=False)\n",
    "    t += \"\"\"\\\\caption{%s}\n",
    "\\\\label{table:%s}\n",
    "\\\\end{table}\n",
    "\"\"\" % (caption, table_name)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(df, grid_param):\n",
    "    # col = ['model', 'attack']\n",
    "    ret = OrderedDict()\n",
    "    tst_df = params_to_dataframe(grid_param, ['tst_score'])\n",
    "\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    models = set([c[0] for c, _ in d.items()])\n",
    "    \n",
    "    prev_col =None\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        new_col_dict = OrderedDict({})\n",
    "        if i == 0:\n",
    "            for row, _ in col_dict.items():\n",
    "                temp_df = tst_df[(tst_df['model'] == col[0].replace(\"-\", \"_\"))\n",
    "                                 & (tst_df['attack'] == 'blackbox') \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        elif '\\\\epsilon' in col[1]:\n",
    "            m = re.match(r\"(?P<attack>[a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", col[1])\n",
    "            attack_name = m.group(\"attack\")[:-9].replace(\"-\", \"_\") # remove '$epsilon$'\n",
    "            for row, row_val in col_dict.items():\n",
    "                if 'd' in col[0].split('-')[-1]:\n",
    "                    model_name = '%s-%d-%s' % ('-'.join(col[0].split('-')[:-1]),\n",
    "                                               int(float(row_val.replace(\"$\", \"\"))*100),\n",
    "                                               col[0].split('-')[-1],)\n",
    "                else:\n",
    "                    model_name = \"%s-%d\" % (col[0], int(float(row_val.replace(\"$\", \"\"))*100))\n",
    "                model_name = model_name.replace(\"-\", \"_\")\n",
    "                temp_df = tst_df[(tst_df['model'] == model_name)\n",
    "                                 & (tst_df['attack'] == attack_name) \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert $\\\\epsilon$', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        prev_col = col\n",
    "        ret[col] = col_dict\n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "#params_to_dataframe(grid_param, ['trnX_len', 'aug_len']).groupby(['dataset', 'model'])['aug_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "#_, exp_name, grid_param, _ = dt_robustness()\n",
    "#_, exp_name, grid_param, _ = rf_robustness()\n",
    "#_, exp_name, grid_param, _ = nn_k3_robustness()\n",
    "#df = params_to_dataframe(grid_param, ['avg_pert', 'tst_score']).groupby(['dataset', 'model'])\n",
    "#df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\tiny\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.0pt}\n",
      "\\begin{tabular}{l|cccc|ccc|cccc|cccc|ccc}\n",
      "\\toprule\n",
      "        & \\multicolumn{4}{c}{1-NN} & \\multicolumn{3}{c}{3-NN} & \\multicolumn{4}{c}{DT} & \\multicolumn{4}{c}{RF} &         \\multicolumn{3}{c}{MLP} \\\\\n",
      "        & regular & AT & Wang's & AP & regular & AT & AP & regular & AT & RS & AP & regular & AT & RS & AP & regular & AT & AP \\\\\n",
      "\\midrule\n",
      "australian &                $1.00$ &                $0.64$ &       $\\mathbf{1.65}$ &       $\\mathbf{1.65}$ &                          $1.00$ &                          $0.68$ &                 $\\mathbf{1.20}$ &                 $1.00$ &                  $2.36$ &            $\\mathbf{5.86}$ &                       $2.37$ &                     $1.00$ &                     $1.07$ &            $\\mathbf{1.12}$ &                     $1.04$ &       $1.00$ &  $\\mathbf{12.10}$ &           $1.22$ \\\\\n",
      "cancer &                $1.00$ &                $0.82$ &                $1.05$ &       $\\mathbf{1.41}$ &                          $1.00$ &                          $1.06$ &                 $\\mathbf{1.39}$ &                 $1.00$ &                  $0.85$ &                     $1.09$ &              $\\mathbf{1.19}$ &                     $1.00$ &                     $0.87$ &            $\\mathbf{1.54}$ &                     $1.26$ &       $1.00$ &   $\\mathbf{3.81}$ &           $1.06$ \\\\\n",
      "covtype &                $1.00$ &                $0.61$ &       $\\mathbf{3.17}$ &       $\\mathbf{3.17}$ &                          $1.00$ &                          $0.81$ &                 $\\mathbf{2.55}$ &                 $1.00$ &                  $1.07$ &                     $2.90$ &              $\\mathbf{4.84}$ &                     $1.00$ &                     $0.93$ &                     $1.59$ &            $\\mathbf{2.10}$ &       $1.00$ &  $\\mathbf{24.25}$ &           $1.92$ \\\\\n",
      "diabetes &                $1.00$ &                $0.83$ &       $\\mathbf{4.69}$ &       $\\mathbf{4.69}$ &                          $1.00$ &                          $0.87$ &                 $\\mathbf{2.97}$ &                 $1.00$ &                  $0.93$ &                     $1.53$ &              $\\mathbf{2.22}$ &                     $1.00$ &                     $1.19$ &                     $1.25$ &            $\\mathbf{2.22}$ &       $1.00$ &   $\\mathbf{4.74}$ &           $1.72$ \\\\\n",
      "f-mnist06 &                $1.00$ &                $0.94$ &                $2.09$ &       $\\mathbf{2.12}$ &                          $1.00$ &                          $0.86$ &                 $\\mathbf{1.47}$ &                 $1.00$ &                  $0.82$ &            $\\mathbf{3.91}$ &                       $1.85$ &                     $1.00$ &                     $0.97$ &                     $1.17$ &            $\\mathbf{1.81}$ &       $1.00$ &   $\\mathbf{4.41}$ &           $1.80$ \\\\\n",
      "f-mnist35 &                $1.00$ &                $0.80$ &                $1.02$ &       $\\mathbf{1.08}$ &                          $1.00$ &                          $0.77$ &                 $\\mathbf{1.05}$ &                 $1.00$ &                  $1.11$ &            $\\mathbf{2.64}$ &                       $2.07$ &                     $1.00$ &                     $0.90$ &                     $1.23$ &            $\\mathbf{1.32}$ &       $1.00$ &   $\\mathbf{3.87}$ &           $1.31$ \\\\\n",
      "fourclass &                $1.00$ &                $0.93$ &       $\\mathbf{3.09}$ &       $\\mathbf{3.09}$ &                          $1.00$ &                          $0.89$ &                 $\\mathbf{3.09}$ &                 $1.00$ &                  $1.06$ &                     $1.23$ &              $\\mathbf{3.04}$ &                     $1.00$ &                     $1.03$ &                     $1.93$ &            $\\mathbf{3.59}$ &       $1.00$ &   $\\mathbf{1.73}$ &           $1.18$ \\\\\n",
      "halfmoon &                $1.00$ &                $1.03$ &                $1.98$ &       $\\mathbf{2.73}$ &                          $1.00$ &                          $0.93$ &                 $\\mathbf{1.92}$ &                 $1.00$ &                  $1.54$ &                     $1.98$ &              $\\mathbf{2.58}$ &                     $1.00$ &                     $1.04$ &                     $1.01$ &            $\\mathbf{1.82}$ &       $1.00$ &   $\\mathbf{1.01}$ &  $\\mathbf{1.01}$ \\\\\n",
      "mnist17 &                $1.00$ &                $0.78$ &                $1.01$ &       $\\mathbf{1.20}$ &                          $1.00$ &                          $0.81$ &                 $\\mathbf{1.13}$ &                 $1.00$ &                  $1.14$ &            $\\mathbf{2.91}$ &                       $1.54$ &                     $1.00$ &                     $0.93$ &                     $1.11$ &            $\\mathbf{1.29}$ &       $1.00$ &   $\\mathbf{3.88}$ &           $1.31$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{\n",
      "Improvement Factor. We measure the ratio of the empirical robustness of the defended classifier over that of the regular (undefended) classifier. A number greater than one indicates that the defense yields a more robust model, \n",
      "while less than one indicates less robustness (higher is better; best is in bold).\n",
      "}\n",
      "\\label{table:compare_defense_avg_pert}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def improvement(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        ret[col] = {}\n",
    "        for row, row_value in col_dict.items():\n",
    "            if i == 0:\n",
    "                ref = col_dict\n",
    "                value = 1.0\n",
    "            elif ref[row] == -1 or row_value == -1:\n",
    "                value = -1.\n",
    "            else:\n",
    "                value = (float(row_value.replace(\"$\", '')) / float(ref[row].replace(\"$\", '')))\n",
    "                \n",
    "            ret[col][row] = \"$%.2f$\" % value\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "_, exp_name, grid_param, _ = compare_defense()\n",
    "avg_caption = \"\"\"\n",
    "Improvement Factor. We measure the ratio of the empirical robustness of the defended classifier over that of the regular (undefended) classifier. A number greater than one indicates that the defense yields a more robust model, \n",
    "while less than one indicates less robustness (higher is better; best is in bold).\n",
    "\"\"\"\n",
    "table_str = table_wrapper(gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[improvement, bold_best]\n",
    "            ), '%s_%s' % (exp_name, 'avg_pert'), caption=avg_caption)\n",
    "table_str = table_str.replace(\"                 knn1 &          adv-nn-k1-30 &     robustv2-nn-k1-30 &     robustv1-nn-k1-30\",\n",
    "                              \"\\multicolumn{4}{c}{1-NN}\")\n",
    "table_str = table_str.replace(\"                           knn3 &                    adv-nn-k3-30 &               robustv1-nn-k3-30\",\n",
    "                              \"\\multicolumn{3}{c}{3-NN}\")\n",
    "table_str = table_str.replace(\"      decision-tree-d5 & adv-decision-tree-d5-30 & robust-decision-tree-d5-30 & robustv1-decision-tree-d5-30\",\n",
    "                              \"\\multicolumn{4}{c}{DT}\")\n",
    "table_str = table_str.replace(\"      random-forest-100-d5 &           adv-rf-100-30-d5 &        robust-rf-100-30-d5 &      robustv1-rf-100-30-d5\",\n",
    "                              \"\\multicolumn{4}{c}{RF}\")\n",
    "table_str = table_str.replace(\" mlp &        adv-mlp-30 &  robustv1-mlp-30\",\n",
    "                              \"\\multicolumn{3}{c}{MLP}\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert & nnopt-k1-all-avg-pert\",\n",
    "                              \"regular & AT & Wang's & AP\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region-avg-pert & rev-nnopt-k3-50-region-avg-pert & rev-nnopt-k3-50-region-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\"dt-attack-opt-avg-pert &  dt-attack-opt-avg-pert &     dt-attack-opt-avg-pert &       dt-attack-opt-avg-pert\",\n",
    "                              \"regular & AT & RS & AP\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert & rf-attack-rev-100-avg-pert\",\n",
    "                              \"regular & AT & RS & AP\")\n",
    "table_str = table_str.replace(\"pgd-avg-pert &      pgd-avg-pert &     pgd-avg-pert\",\n",
    "                              \"regular & AT & AP\")\n",
    "table_str = table_str.replace(\"adv-nnopt-k1-all-avg-pert\", \"AT\")\n",
    "table_str = table_str.replace(\"robustv1-nn-k1-30\", \"AP\")\n",
    "table_str = table_str.replace(\"adv-decision-tree-d5-30\", \"AT\")\n",
    "table_str = table_str.replace(\"robustv1-decision-tree-d5-30\", \"AP\")\n",
    "table_str = table_str.replace(\"lllllllllllllllllll\", \"l|cccc|ccc|cccc|cccc|ccc\")\n",
    "print(table_str)\n",
    "#for k, v in variable_name['dataset'].items():\n",
    "#    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\tiny\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.0pt}\n",
      "\\begin{tabular}{l|ccc|ccc|ccc|cc}\n",
      "\\toprule\n",
      "        & \\multicolumn{3}{c}{1-NN} & \\multicolumn{3}{c}{3-NN} & \\multicolumn{3}{c}{DT} & \\multicolumn{2}{c}{RF} \\\\\n",
      "        & Direct & BBox & RBA-Exact & Direct & BBox & RBA-Approx & Papernot's & BBox & RBA-Exact &    BBox & RBA-Approx \\\\\n",
      "\\midrule\n",
      "australian &    $\\mathbf{1.00}$ &            $0.76$ &                $0.34$ &    $\\mathbf{1.00}$ &            $0.54$ &                          $0.39$ &       $\\mathbf{1.00}$ &            $0.99$ &                 $0.50$ &               $1.00$ &            $\\mathbf{1.23}$ \\\\\n",
      "cancer &    $\\mathbf{1.00}$ &            $0.96$ &                $0.39$ &    $\\mathbf{1.00}$ &            $0.96$ &                          $0.51$ &       $\\mathbf{1.00}$ &            $0.67$ &                 $0.56$ &      $\\mathbf{1.00}$ &                     $0.90$ \\\\\n",
      "covtype &    $\\mathbf{1.00}$ &            $0.65$ &                $0.24$ &    $\\mathbf{1.00}$ &            $0.60$ &                          $0.27$ &       $\\mathbf{1.00}$ &            $0.40$ &                 $0.24$ &      $\\mathbf{1.00}$ &                     $0.86$ \\\\\n",
      "diabetes &    $\\mathbf{1.00}$ &            $0.64$ &                $0.20$ &    $\\mathbf{1.00}$ &            $0.84$ &                          $0.46$ &       $\\mathbf{1.00}$ &            $0.56$ &                 $0.36$ &               $1.00$ &            $\\mathbf{1.02}$ \\\\\n",
      "f-mnist06 &    $\\mathbf{1.00}$ &            $0.63$ &                $0.13$ &    $\\mathbf{1.00}$ &            $0.79$ &                          $0.27$ &       $\\mathbf{1.00}$ &            $0.91$ &                 $0.57$ &      $\\mathbf{1.00}$ &                     $0.90$ \\\\\n",
      "f-mnist35 &    $\\mathbf{1.00}$ &            $0.76$ &                $0.25$ &    $\\mathbf{1.00}$ &            $0.79$ &                          $0.31$ &       $\\mathbf{1.00}$ &            $0.59$ &                 $0.39$ &               $1.00$ &            $\\mathbf{1.22}$ \\\\\n",
      "fourclass &    $\\mathbf{1.00}$ &            $0.96$ &                $0.62$ &             $1.00$ &   $\\mathbf{1.03}$ &                          $0.70$ &       $\\mathbf{1.00}$ &            $0.67$ &                 $0.48$ &      $\\mathbf{1.00}$ &                     $0.81$ \\\\\n",
      "halfmoon &             $1.00$ &   $\\mathbf{1.84}$ &                $0.84$ &             $1.00$ &   $\\mathbf{1.26}$ &                          $0.91$ &                $1.00$ &   $\\mathbf{1.51}$ &                 $0.87$ &      $\\mathbf{1.00}$ &                     $0.82$ \\\\\n",
      "mnist17 &    $\\mathbf{1.00}$ &            $0.79$ &                $0.24$ &    $\\mathbf{1.00}$ &            $0.87$ &                          $0.32$ &       $\\mathbf{1.00}$ &            $0.74$ &                 $0.50$ &               $1.00$ &            $\\mathbf{1.03}$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Empirical robustness (measured in $\\ell_\\infty$) to alter all predictions (lower is better; best is in bold).}\n",
      "\\label{table:compare_attacks_avg_pert}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_param, _ = compare_attacks()\n",
    "avg_caption = \"Empirical robustness (measured in $\\ell_\\infty$) to alter all predictions (lower is better; best is in bold).\"\n",
    "table_str = table_wrapper(gen_table(\n",
    "                exp_name, grid_param, ['model', 'attack'], ['dataset'], combine_method=1,\n",
    "                objs=['avg_pert'], additionals=[improvement, bold_best]\n",
    "            ), '%s_%s' % (exp_name, 'avg_pert'), caption=avg_caption)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"llllllllllll\", \"l|ccc|ccc|ccc|cc\")\n",
    "table_str = table_str.replace(\"-avg-pert\", \"\")\n",
    "table_str = table_str.replace(\"direct-k1\", \"Direct\")\n",
    "table_str = table_str.replace(\"direct-k3\", \"Direct\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all\", \"RBA-Exact\")\n",
    "table_str = table_str.replace(\"dt-papernots\", \"Papernot's\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"RBA-Approx\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-100\", \"RBA-Approx\")\n",
    "table_str = table_str.replace(\"dt-attack-opt\", \"RBA-Exact\")\n",
    "table_str = table_str.replace(\"decision-tree-d5\", \"DT\")\n",
    "table_str = table_str.replace(\"random-forest-100-d5\", \"RF\")\n",
    "table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "table_str = table_str.replace(\"\\multicolumn{3}{l}\", \"\\multicolumn{3}{c}\")\n",
    "table_str = table_str.replace(\"\\multicolumn{2}{l}\", \"\\multicolumn{2}{c}\")\n",
    "table_str = table_str.replace(\"blackbox\", \"BBox\")\n",
    "#for k, v in variable_name['dataset'].items():\n",
    "#    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "print(table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fns = [nn_k1_robustness_figs, nn_k3_robustness_figs, dt_robustness_figs, rf_robustness_figs]\n",
    "model_names = [\"1-NN\", \"3-NN\", \"Decision tree\", \"Random forest\"]\n",
    "def get_label_name(name):\n",
    "    if 'robustv1' in name:\n",
    "        return \"AP\"\n",
    "    elif 'robust' in name:\n",
    "        return \"RS\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"Reg.\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"Reg.\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_label_color(name):\n",
    "    if 'robustv1' in name:\n",
    "        return \"#ff7f0e\"\n",
    "    elif 'robust' in name:\n",
    "        return \"#1f77b4\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"#7f7f7f\"\n",
    "    elif 'random_forest' in name:\n",
    "        return \"#7f7f7f\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=False):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    \n",
    "    fig_paths = plot_result(df, exp_name, control, variables,\n",
    "                            get_title_fn=lambda g: g['dataset'],\n",
    "                            get_label_name_fn=get_label_name,\n",
    "                            get_label_color_fn=get_label_color,\n",
    "                            show_plot=show_plot)\n",
    "    return fig_paths\n",
    "\n",
    "def fig_paths_latex(fig_paths: List[List[Tuple[Dict, str]]], fig_label, caption):\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for row in fig_paths:\n",
    "        for entry in row:\n",
    "            g, img_path = entry\n",
    "            ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=%.2f\\\\textwidth]{%s}}\"\"\" % (g['subfig_label'], 1/len(fig_paths[0]), img_path)\n",
    "        ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, fig_label)\n",
    "    return ret\n",
    "\n",
    "fig_paths = []\n",
    "for i, fn in enumerate(exp_fns):\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    fig_path = compare_nn_plots(exp_name, grid_param, show_plot=False)\n",
    "    for g, _ in fig_path:\n",
    "        g['subfig_label'] = model_names[i]\n",
    "        for k, v in variable_name['dataset'].items():\n",
    "            g['subfig_label'] = re.sub(k, v, g['subfig_label'])\n",
    "    fig_paths.append(fig_path)\n",
    "transpose = [list() for c in fig_paths[0]]\n",
    "for i, col in enumerate(fig_paths):\n",
    "    for j, r in enumerate(col):\n",
    "        transpose[j].append(r)\n",
    "        \n",
    "caption = \"The maximum perturbation distance allowed versus accuracy\"\n",
    "fig_str = fig_paths_latex(transpose[:5], \"defense-cmp\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp_fig.tex')\n",
    "\n",
    "fig_str = fig_paths_latex(transpose[5:], \"defense-cmp2\", caption)\n",
    "write_to_tex(fig_str, 'defense_cmp2_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{figure}[ht!]\n",
      "\\centering\n",
      "\\subfloat[halfmoon]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_halfmoon_2200_inf.eps}}\n",
      "\\subfloat[mnist17]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_mnist17_2200_pca25_inf.eps}}\n",
      "\\subfloat[fourclass]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_fourclass_inf.eps}}\n",
      "\\subfloat[f-mnist06]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_fashion_mnist06_2200_pca25_inf.eps}}\n",
      "\n",
      "\\subfloat[australian]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_australian_inf.eps}}\n",
      "\\subfloat[cancer]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_cancer_inf.eps}}\n",
      "\\subfloat[covtype]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_covtypebin_1200_inf.eps}}\n",
      "\\subfloat[diabetes]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_diabetes_inf.eps}}\n",
      "\n",
      "\\subfloat[f-mnist35]{\n",
      "    \\includegraphics[width=0.25\\textwidth]{./figs/compare_nns_fashion_mnist35_2200_pca25_inf.eps}}\n",
      "\n",
      "\\caption{}\n",
      "\\label{fig:compare_nns}\n",
      "\\end{figure} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_param, _ = compare_nns()\n",
    "\n",
    "def get_title_fn(g):\n",
    "    ret = g['dataset']\n",
    "    for k, v in variable_name['dataset'].items():\n",
    "        ret = re.sub(k.replace('_', '-'), v, ret)\n",
    "    return ret\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    figs = plot_result(df, exp_name, control, variables, get_title_fn=get_title_fn, show_plot=show_plot)\n",
    "    fig_paths = []\n",
    "    for i, f in enumerate(figs):\n",
    "        if i % 4 == 0:\n",
    "            fig_paths.append([])\n",
    "        f[0]['subfig_label'] = f[0]['dataset']\n",
    "        for k, v in variable_name['dataset'].items():\n",
    "            f[0]['subfig_label'] = re.sub(k, v, f[0]['subfig_label'])\n",
    "        fig_paths[-1].append(f)\n",
    "    \n",
    "    return fig_paths_latex(fig_paths, exp_name, caption=caption)\n",
    "    #return result_latex_figs(exp_name, control, caption)\n",
    "fig_str = compare_nn_plots(exp_name, grid_param, show_plot=False)\n",
    "print(fig_str)\n",
    "write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\tiny\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{2.0pt}\n",
      "\\begin{tabular}{lcccc|cccc|cccc|cccc}\n",
      "\\toprule\n",
      "        & \\multicolumn{4}{c}{1-NN} & \\multicolumn{4}{c}{3-NN} & \\multicolumn{4}{c}{DT} & \\multicolumn{4}{c}{RF} \\\\\n",
      "        & Regular & AP-10 & AP-30 & AP-50 & Regular & AP-10 & AP-30 & AP-50 & Regular & AP-10 & AP-30 & AP-50  & Regular & AP-10 & AP-30 & AP-50 \\\\\n",
      "\\midrule\n",
      "australian &                 $.805$ &                 $.800$ &                 $.820$ &                 $.825$ &                           $.805$ &                           $.810$ &                           $.815$ &                           $.825$ &                  $.855$ &                       $.835$ &                       $.835$ &                       $.835$ &                      $.845$ &                      $.855$ &                      $.840$ &                      $.835$ \\\\\n",
      "cancer &                 $.950$ &                 $.950$ &                 $.950$ &                 $.965$ &                           $.975$ &                           $.975$ &                           $.960$ &                           $.970$ &                  $.930$ &                       $.930$ &                       $.965$ &                       $.960$ &                      $.970$ &                      $.970$ &                      $.965$ &                      $.955$ \\\\\n",
      "covtype &                 $.670$ &                 $.680$ &                 $.680$ &                 $.710$ &                           $.690$ &                           $.675$ &                           $.685$ &                           $.710$ &                  $.715$ &                       $.710$ &                       $.670$ &                       $.670$ &                      $.705$ &                      $.720$ &                      $.665$ &                      $.640$ \\\\\n",
      "diabetes &                 $.695$ &                 $.700$ &                 $.660$ &                 $.660$ &                           $.755$ &                           $.750$ &                           $.655$ &                           $.660$ &                  $.715$ &                       $.720$ &                       $.670$ &                       $.670$ &                      $.755$ &                      $.740$ &                      $.660$ &                      $.660$ \\\\\n",
      "f-mnist06 &                 $.790$ &                 $.790$ &                 $.755$ &                 $.450$ &                           $.795$ &                           $.790$ &                           $.730$ &                           $.450$ &                  $.815$ &                       $.805$ &                       $.705$ &                       $.490$ &                      $.795$ &                      $.800$ &                      $.750$ &                      $.490$ \\\\\n",
      "f-mnist35 &                 $.990$ &                 $.990$ &                $1.000$ &                 $.980$ &                           $.995$ &                           $.995$ &                           $.995$ &                           $.975$ &                  $.995$ &                       $.995$ &                       $.900$ &                       $.910$ &                     $1.000$ &                     $1.000$ &                      $.925$ &                      $.910$ \\\\\n",
      "fourclass &                $1.000$ &                 $.960$ &                 $.750$ &                 $.565$ &                           $.995$ &                           $.960$ &                           $.750$ &                           $.565$ &                  $.900$ &                       $.910$ &                       $.680$ &                       $.565$ &                      $.980$ &                      $.865$ &                      $.665$ &                      $.565$ \\\\\n",
      "halfmoon &                 $.920$ &                 $.915$ &                 $.840$ &                 $.480$ &                           $.940$ &                           $.920$ &                           $.845$ &                           $.480$ &                  $.950$ &                       $.895$ &                       $.670$ &                       $.480$ &                      $.930$ &                      $.900$ &                      $.755$ &                      $.480$ \\\\\n",
      "mnist17 &                 $.995$ &                 $.995$ &                 $.975$ &                 $.670$ &                           $.995$ &                           $.995$ &                           $.975$ &                           $.655$ &                  $.985$ &                       $.985$ &                       $.975$ &                       $.865$ &                      $.990$ &                      $.990$ &                      $.965$ &                      $.860$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{test accuracy with different defense strength}\n",
      "\\label{table:tst_scores}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_param, _ = tst_scores()\n",
    "avg_caption = \"test accuracy with different defense strength\"\n",
    "df = gen_table(exp_name, grid_param, ['model', 'attack'], ['dataset'],\n",
    "               combine_method=1, objs=['tst_score'], additionals=[])\n",
    "table_str = table_wrapper(df, table_name=exp_name, caption=avg_caption,)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lllllllllllllllll\", \"lcccc|cccc|cccc|cccc\")\n",
    "#table_str = table_str.replace(\"nnopt-k1-all\", \"RBA-Exact\")\n",
    "table_str = table_str.replace(\"                  knn1 &      robustv1-nn-k1-10 &      robustv1-nn-k1-30 &      robustv1-nn-k1-50\",\n",
    "                              \"\\multicolumn{4}{c}{1-NN}\")\n",
    "table_str = table_str.replace(\"                            knn3 &                robustv1-nn-k3-10 &                robustv1-nn-k3-30 &                robustv1-nn-k3-50\",\n",
    "                              \"\\multicolumn{4}{c}{3-NN}\")\n",
    "table_str = table_str.replace(\"       decision-tree-d5 & robustv1-decision-tree-d5-10 & robustv1-decision-tree-d5-30 & robustv1-decision-tree-d5-50\",\n",
    "                              \"\\multicolumn{4}{c}{DT}\")\n",
    "table_str = table_str.replace(\"       random-forest-100-d5 &       robustv1-rf-100-10-d5 &       robustv1-rf-100-30-d5 &       robustv1-rf-100-50-d5\",\n",
    "                              \"\\multicolumn{4}{c}{RF}\")\n",
    "#table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all-tst-score & \" * 4,\n",
    "                              \"Regular & AP-10 & AP-30 & AP-50 & \")\n",
    "table_str = table_str.replace(\"& rev-nnopt-k3-50-region-tst-score \" * 4,\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "table_str = table_str.replace(\"& dt-attack-opt-tst-score &      dt-attack-opt-tst-score &      dt-attack-opt-tst-score &      dt-attack-opt-tst-score\",\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "table_str = table_str.replace(\"& rf-attack-rev-100-tst-score \" * 4,\n",
    "                              \"& Regular & AP-10 & AP-30 & AP-50 \")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "print(table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "table_wrapper() got multiple values for argument 'caption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-81fb967fbd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data set statistics\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtable_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'n_samples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#write_to_tex(table_str, exp_name + '_table.tex')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: table_wrapper() got multiple values for argument 'caption'"
     ]
    }
   ],
   "source": [
    "_, _, grid_param, _ = nn_k1_robustness()\n",
    "datasets = union_param_key(grid_param, 'dataset')\n",
    "exp_name = \"dataset-stats\"\n",
    "grid_param = {\"dataset\": datasets,}\n",
    "caption = \"Dataset statistics.\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'n_classes'], ['dataset'], caption=caption)\n",
    "print(table_str)\n",
    "#write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash ./sync_report.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-788ee363e0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_k3_robustness()\n",
    "avg_caption = \"3-NN average perturbation distance (Linf)\"\n",
    "#table_str = table_wrapper(exp_name, grid_param, ['model', 'attack'], ['dataset'], caption=avg_caption, additionals=[cmp_ratio])\n",
    "#table_str = re.sub(\"([a-zA-Z_0-9'-]*) imp\\.\", \"imp.\", table_str)\n",
    "#write_to_tex(table_str, exp_name + '_table.tex')\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"our-50\")\n",
    "table_str = table_str.replace(\"robustv1-nn-k3\", \"3-NN with adversarial pruning\")\n",
    "table_str = table_str.replace(\"blackbox\", \"BBox\")\n",
    "table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_robustness()\n",
    "avg_caption = \"Random forest average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"random-forest-100-d5\", \"random forest\")\n",
    "table_str = table_str.replace(\"robust-rf-100-d5\", \"random forest with robust splitting\")\n",
    "table_str = table_str.replace(\"robustv1-rf-100-d5\", \"random forest with adversarial pruning\")\n",
    "\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = dt_robustness()\n",
    "avg_caption = \"Decision tree average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"llllllllllllllllllllllllllll\", \"llll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"dt-attack-opt\", \"opt\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_k1_optimality_figs()\n",
    "df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "datasets = union_param_key(grid_param, 'dataset')\n",
    "for dataset in datasets:\n",
    "    temp_df = df[(df['dataset'] == dataset)]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(dataset)\n",
    "    x = []\n",
    "    for k, v in temp_df.groupby(\"attack\"):\n",
    "        avg_pert = v['avg_pert'].mean()\n",
    "        if k == 'blackbox':\n",
    "            bb_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='Cheng', colors='c')\n",
    "        elif k.split('_')[-1] == 'all':\n",
    "            opt_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='opt')\n",
    "        elif k.split('_')[-1] == 'rev':\n",
    "            x.append((100, avg_pert))\n",
    "        else:\n",
    "            if k.split('_')[-1] != 'region':\n",
    "                x.append((int(k.split('_')[-1]), avg_pert))\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "    x = sorted(x, key=lambda t: t[0])\n",
    "    x, y = zip(*x)\n",
    "    ax.plot(x, y)\n",
    "    set_plot(fig, ax)\n",
    "    ax.set_ylim(opt_avg-0.03, max(list(y) + [bb_avg])+0.03)\n",
    "    ax.set_xlim(0, 100)\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in [nn_k1_robustness_figs, nn_k3_robustness_figs]:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "    datasets = union_param_key(grid_param, 'dataset')\n",
    "    for dataset in datasets:\n",
    "        temp_df = df[(df['dataset'] == dataset)]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(dataset)\n",
    "        x = []\n",
    "        for k, v in temp_df.groupby(\"attack\"):\n",
    "            avg_pert = v['avg_pert'].mean()\n",
    "            if k == 'blackbox':\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='Cheng')\n",
    "            elif k.split('_')[-1] == 'all':\n",
    "                opt_pert = avg_pert\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='opt')\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "        x = sorted(x, key=lambda t: t[0])\n",
    "        x, y = zip(*x)\n",
    "        ax.plot(x, y)\n",
    "        set_plot(fig, ax)\n",
    "        ax.set_ylim(opt_pert-0.03, max(y)+0.03)\n",
    "        ax.set_xlim(0, 50)\n",
    "        #ax.set_xscale('log')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_optimality()\n",
    "avg_caption = \"RF average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_optimality()\n",
    "avg_caption = \"3NN average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"nnopt-k3-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [rf_attack, opt_of_rf_attack, robust_rf]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    #columns = ['blackbox', 'rf_attack_rev_20', 'rf_attack_rev_100']\n",
    "    table_str = table_wrapper(exp_name, grid_param, ['attack'], ['dataset'], caption=avg_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(grid_param)\n",
    "    variables = grid_param[0]['attack']\n",
    "    #variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    #print(table_str)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnattack.models.robust_nn.eps_separation import build_collision_graph, find_min_cover\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=3)\n",
    "\n",
    "auto_var.set_variable_value(\"random_seed\", 0)\n",
    "np.random.seed(0)\n",
    "X, y, _ = auto_var.get_var_with_argument(\"dataset\", \"mnist17_2200\")\n",
    "pts = PCA().fit_transform(X)\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "pts = MinMaxScaler().fit_transform(pts)\n",
    "\n",
    "nn.fit(pts)\n",
    "y_pts = [1 if i>0 else -1 for i in y]\n",
    "adj_lst, graph = build_collision_graph(0.15, pts, y_pts, np.inf)\n",
    "matching, min_cover = find_min_cover(graph, adj_lst, y_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[list(min_cover)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in min_cover:\n",
    "    _, idx = nn.kneighbors([pts[i]])\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.savefig(f'/home/arbiter/figs/{i}.png', format='png')\n",
    "    plt.close()\n",
    "    mkdir_p(f'/home/arbiter/figs/{i}')\n",
    "    for j in idx[0]:\n",
    "        print(j, X.shape)\n",
    "        plt.imshow(X[j].reshape(28, 28))\n",
    "        plt.savefig(f'/home/arbiter/figs/{i}/{j}.png', format='png')\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
