{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from functools import reduce, partial\n",
    "from collections import OrderedDict\n",
    "import pprint\n",
    "from mkdir_p import mkdir_p\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from nnattack.variables import auto_var\n",
    "from params import (\n",
    "    compare_attacks,\n",
    "    \n",
    "    compare_nns,\n",
    "    nn_k1_robustness,\n",
    "    nn_k3_robustness,\n",
    "    \n",
    "    rf_robustness,\n",
    "    dt_robustness,\n",
    "    \n",
    "    dt_robustness_figs,\n",
    "    nn_k1_robustness_figs,\n",
    "    nn_k3_robustness_figs,\n",
    "    rf_optimality_figs,\n",
    "    nn_k1_optimality_figs,\n",
    "    nn_k3_optimality_figs,\n",
    ")\n",
    "from utils import set_plot, get_result, write_to_tex, union_param_key, params_to_dataframe\n",
    "\n",
    "auto_var.set_variable_value('random_seed', 0)\n",
    "auto_var.set_variable_value('ord', 'inf')\n",
    "auto_var.set_logging_level(0)\n",
    "\n",
    "compare_attacks = compare_attacks()\n",
    "compare_nns = compare_nns()\n",
    "nn_k1_robustness = nn_k1_robustness()\n",
    "nn_k3_robustness = nn_k3_robustness()\n",
    "rf_robustness = rf_robustness()\n",
    "dt_robustness = dt_robustness()\n",
    "dt_robustness_figs = dt_robustness_figs()\n",
    "nn_k1_robustness_figs = nn_k1_robustness_figs()\n",
    "nn_k3_robustness_figs = nn_k3_robustness_figs()\n",
    "rf_optimality_figs = rf_optimality_figs()\n",
    "nn_k1_optimality_figs = nn_k1_optimality_figs()\n",
    "nn_k3_optimality_figs = nn_k3_optimality_figs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_latex_figs(exp_name, control_var, caption):\n",
    "    control = ParameterGrid(control_var)\n",
    "    ret = \"\"\"\n",
    "\\\\begin{figure}[ht!]\n",
    "\\\\centering\"\"\"\n",
    "    img_paths = []\n",
    "    for i, g in enumerate(control):\n",
    "        dataset, ord = g['dataset'], g['ord']\n",
    "        img_path = f'./figs/{exp_name}_{dataset}_{ord}.eps'\n",
    "        dataset = dataset.replace(\"_\", \" \")\n",
    "        ret += \"\"\"\n",
    "\\\\subfloat[%s]{\n",
    "    \\\\includegraphics[width=.45\\\\textwidth]{%s}}\"\"\" % (dataset, img_path)\n",
    "        if i % 2 == 1:\n",
    "            ret += \"\\n\"\n",
    "    ret += \"\"\"\n",
    "\\\\caption{%s}\n",
    "\\\\label{fig:%s}\n",
    "\\\\end{figure} \n",
    "\"\"\" % (caption, exp_name)\n",
    "    return ret\n",
    "                      \n",
    "def plot_result(df, exp_name, control_var, variables, get_title=None, get_label_name=None, show_plot=True):\n",
    "    for g in ParameterGrid(control_var):\n",
    "        temp_df = df\n",
    "                      \n",
    "        if get_title is None:\n",
    "            title = exp_name\n",
    "            for k, v in g.items():\n",
    "                if v in variable_name[k]:\n",
    "                    title = title + f\"_{variable_name[k][v]}\"\n",
    "                else:\n",
    "                    title = title + f\"_{v}\"\n",
    "                temp_df = temp_df.loc[df[k] == v]\n",
    "        else:\n",
    "            title = get_title(g)\n",
    "                      \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(title)\n",
    "        for name, group in temp_df.groupby(variables):\n",
    "            #print(name, len(group))\n",
    "            eps_list = [re.findall(r'[-+]?\\d*\\.\\d+|\\d+', t)[0] for t in group.mean().index.tolist()[:-1]]\n",
    "            s = [r for r in group.mean().tolist()[:-1] if not np.isnan(r)]\n",
    "            x = [float(eps_list[i]) for i, r in enumerate(group.mean().tolist()[:-1]) if not np.isnan(r)]\n",
    "                      \n",
    "            if get_label_name is not None:\n",
    "                label = get_label_name(name)\n",
    "            elif isinstance(name, str):\n",
    "                if variables[0] not in variable_name:\n",
    "                    label = name\n",
    "                elif name in variable_name[variables[0]]:\n",
    "                    label = variable_name[variables[0]][name]\n",
    "                else:\n",
    "                    label = name\n",
    "            else:\n",
    "                mod_names = []\n",
    "                for i, n in enumerate(name):\n",
    "                    if n in variable_name[variables[i]]:\n",
    "                        mod_names.append(variable_name[variables[i]][n])\n",
    "                    else:\n",
    "                        mod_names.append(n)\n",
    "                label = mod_name.join(\"_\")\n",
    "            ax.plot(x, s, label=label)\n",
    "\n",
    "        dataset = g['dataset']\n",
    "        ord = g['ord']\n",
    "        set_plot(fig, ax)\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        if show_plot:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "                      \n",
    "variable_name = {\n",
    "    #'model': {\n",
    "    #    ''\n",
    "    #},\n",
    "    'dataset': {\n",
    "        r\"fashion_mnist35_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'f-mnist35',\n",
    "        r\"fashion_mnist06_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'f-mnist06',\n",
    "        r\"mnist17_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'mnist17',\n",
    "        r\"mnist35_(?P<samples>\\d+)(?P<dims>_pca\\d+)?\": 'mnist35',\n",
    "        r\"digits(?P<dims>_\\d+)?\": 'digits',\n",
    "        r\"halfmoon_(?P<samples>\\d+)\": 'halfmoon',\n",
    "        r\"ijcnn1_(?P<samples>\\d+)\": 'ijcnn',\n",
    "        \n",
    "        'abalone': 'abalone',\n",
    "        'iris': 'iris',\n",
    "        'wine': 'wine',\n",
    "        'covtype_3200': 'covtype',\n",
    "    },\n",
    "    'attack': {\n",
    "        'blackbox': 'Cheng\\'s',\n",
    "        'kernelsub_c10000_pgd': 'kernelsub',\n",
    "        'kernelsub_c1000_pgd': 'kernelsub',\n",
    "        'rev_nnopt_k1_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k1_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k1_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k1_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k3_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k3_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k3_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k3_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k5_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k5_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k5_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k5_50_region': 'nnopt-50',\n",
    "        'rev_nnopt_k7_20': 'nnopt-20-ori',\n",
    "        'rev_nnopt_k7_50': 'nnopt-50-ori',\n",
    "        'rev_nnopt_k7_20_region': 'nnopt-20',\n",
    "        'rev_nnopt_k7_50_region': 'nnopt-50',\n",
    "        \n",
    "        'nnopt_k1_all': 'nnopt-all',\n",
    "        'nnopt_k3_all': 'nnopt-all',\n",
    "        \n",
    "        'direct_k1': 'direct attack',\n",
    "        'direct_k3': 'direct attack',\n",
    "        'direct_k5': 'direct attack',\n",
    "        'direct_k7': 'direct attack',\n",
    "        \n",
    "        'rf_attack_all': 'RF-all',\n",
    "        'rf_attack_rev': 'RF-rev',\n",
    "        'rf_attack_rev_20': 'RF-rev-20',\n",
    "        'rf_attack_rev_50': 'RF-rev-50',\n",
    "        'rf_attack_rev_100': 'RF-rev-100',\n",
    "    },\n",
    "    'ord': {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_attack_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['attack']\n",
    "    plot_result(df, exp_name, control, variables, show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "    \n",
    "def get_var_name(var, arg):\n",
    "    if var == 'model':\n",
    "        if 'adv' in arg or 'robust' in arg:\n",
    "            arg = \"%s_%02d\" % (\"_\".join(arg.split(\"_\")[:-1]), int(arg.split(\"_\")[-1]))\n",
    "        else:\n",
    "            arg = arg\n",
    "    else:\n",
    "        arg = variable_name[var].get(arg, arg)\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def get_var_name(var, arg):\n",
    "    return arg.replace('_', '-')\n",
    "\n",
    "def avg_pert_table(exp_name, grid_param, columns, rows, objs:list=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    columns = list(filter(lambda a: a not in ['n_features', 'n_samples', 'n_classes'], columns))\n",
    "    if len(columns) == 0 or len(rows) == 0:\n",
    "        return pd.DataFrame({})\n",
    "    df = params_to_dataframe(grid_param, objs)\n",
    "    \n",
    "    d = {}\n",
    "    col_grid = OrderedDict({c: union_param_key(grid_param, c) for c in columns})\n",
    "    row_grid = OrderedDict({r: union_param_key(grid_param, r) for r in rows})\n",
    "    for obj in objs:\n",
    "        temp_df = df.groupby(columns + rows)[obj].mean()\n",
    "        temp_df_sem = df.groupby(columns + rows)[obj].sem()\n",
    "        \n",
    "        if obj == 'tst_score':\n",
    "            assert columns[0] == 'model'\n",
    "        for col in ParameterGrid(col_grid):\n",
    "            col_k = tuple(col[c] for c in columns)\n",
    "            col_name = tuple([get_var_name(c, col[c]) for c in columns[:-1]] \\\n",
    "                             + [\"%s-%s\" % (get_var_name(columns[-1], col[columns[-1]]), obj.replace(\"_\", \"-\"))])\n",
    "            d[col_name] = {}\n",
    "            for row in ParameterGrid(row_grid):\n",
    "                row_k = tuple(row[r] for r in rows)\n",
    "                row_name = tuple(get_var_name(r, row[r]) for r in rows)\n",
    "                if (col_k + row_k) in temp_df:\n",
    "                    #d[col_name][row_name] = \"$%.3f \\pm %.3f$\" % (temp_df[col_k + row_k], temp_df_sem[col_k + row_k])\n",
    "                    d[col_name][row_name] = \"$%.3f$\" % (temp_df[col_k + row_k])\n",
    "                    d[col_name][row_name] = d[col_name][row_name].replace(\"0.\", \".\")\n",
    "                else:\n",
    "                    d[col_name][row_name] = -1\n",
    "\n",
    "    d = {k: d[k] for k in sorted(d.keys())}\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def dataset_stat_column(df, grid_param, columns, rows):\n",
    "    if (\"n_features\" not in columns) and (\"n_samples\" not in columns) and (\"n_classes\" not in columns):\n",
    "        return df\n",
    "    \n",
    "    column_names = {\n",
    "        'n_features': '\\# features',\n",
    "        'n_samples': '\\# examples',\n",
    "        'n_classes': '\\# classes',\n",
    "    }\n",
    "    \n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    datasets = union_param_key(grid_param, \"dataset\")\n",
    "    if len(d.keys()) > 0:\n",
    "        first_key = list(d.keys())[0]\n",
    "        row_len = 1 if isinstance(d[first_key], str) else len(first_key)\n",
    "        col_len = 1 if isinstance(first_key, str) else len(first_key)\n",
    "        ori_cols = list(d.keys())\n",
    "    else:\n",
    "        row_len = 1\n",
    "        col_len = 1\n",
    "        ori_cols = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X, y, _ = auto_var.get_var_with_argument(\"dataset\", dataset)\n",
    "        row_name = (get_var_name(\"dataset\", dataset), )\n",
    "        for col in columns:\n",
    "            if col not in column_names:\n",
    "                continue\n",
    "            column_name = tuple(['-' for _ in range(col_len-1)] + [column_names[col]])\n",
    "            if col == \"n_features\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[1]\n",
    "            elif col == \"n_samples\":\n",
    "                d.setdefault(column_name, {})[row_name] = X.shape[0]\n",
    "            elif col == \"n_classes\":\n",
    "                d.setdefault(column_name, {})[row_name] = len(np.unique(y))\n",
    "                \n",
    "    for col in ori_cols:\n",
    "        d.move_to_end(col)\n",
    "        \n",
    "    return pd.DataFrame(d)\n",
    "    \n",
    "def cmp_ratio(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    cmp_base = []\n",
    "    \n",
    "    i = 0\n",
    "    for col, col_dict in d.items():\n",
    "        ret[col] = col_dict\n",
    "        if 'avg-pert' not in col[1]:\n",
    "            continue\n",
    "        if i == 0 or i == 1:\n",
    "            cmp_base.append(col_dict)\n",
    "            i += 1\n",
    "            continue\n",
    "        temp = {}\n",
    "        for k, v in col_dict.items():\n",
    "            if v == -1 or cmp_base[i % 2][k] == -1:\n",
    "                temp[k] = int(-1)\n",
    "            else:\n",
    "                v = v.replace(\"$\", \"\")\n",
    "                t = cmp_base[i % 2][k].replace(\"$\", \"\")\n",
    "                temp[k] = \"$%.2f$\" % (float(v) / float(t))\n",
    "        \n",
    "        ret[tuple([c for c in col[:-1]] + [\"%s imp.\" % col[-1]])] = temp\n",
    "        i += 1\n",
    "        #ret[tuple([c for c in col[:-1]] + [\"%d imp.\" % i])] = temp\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def max_imp(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    def add_new_col(col_list, ret):\n",
    "        new_col = {}\n",
    "        \n",
    "        for attack_name in [col_list[0][0][1], col_list[1][0][1]]:\n",
    "            temp = list(filter(lambda t: t[0][1] == attack_name, col_list))\n",
    "            imps = []\n",
    "            for c in temp:\n",
    "                imps.append([float(v.replace(\"$\", \"\")) if v != -1 else -1 for _, v in c[1].items()])\n",
    "            imps = (np.array(imps).T).argmax(axis=1)\n",
    "\n",
    "            new_col = {}\n",
    "            new_col_imp = {}\n",
    "            new_col_eps = {}\n",
    "            pcol = temp[0][0]\n",
    "            \n",
    "            if 'd' in pcol[0].split(\"-\")[-1]:\n",
    "                tt = pcol[0].split(\"-\")\n",
    "                tt.pop(-2)\n",
    "            else:\n",
    "                tt = pcol[0].split(\"-\")[:-1]\n",
    "            new_col_name = (\"-\".join(tt), pcol[1])\n",
    "            new_col_imp_name = (\"-\".join(tt), (\"%s imp.\" % pcol[1]))\n",
    "            new_col_eps_name = (\"-\".join(tt), (\"%s $\\\\epsilon$\" % pcol[1]))\n",
    "            for i, idx in enumerate(imps):\n",
    "                k, v = list(temp[idx][1].items())[i]\n",
    "                new_col[k] = v\n",
    "                k, v = list(temp[idx][2].items())[i]\n",
    "                new_col_imp[k] = v \n",
    "\n",
    "                if 'd' in temp[idx][0][0].split(\"-\")[-1]:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-2]) * 0.01))[1:]\n",
    "                else:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-1]) * 0.01))[1:]\n",
    "\n",
    "            ret[new_col_eps_name] = new_col_eps\n",
    "            ret[new_col_name] = new_col\n",
    "            ret[new_col_imp_name] = new_col_imp\n",
    "    \n",
    "    prev_col = None\n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if 'd' in col[0].split(\"-\")[-1]:\n",
    "            check_idx = -2\n",
    "        else:\n",
    "            check_idx = -1\n",
    "            \n",
    "        if i == 0 or i == 1:\n",
    "            ret[col] = col_dict\n",
    "            continue\n",
    "            \n",
    "        if len(temp) == 0:\n",
    "            temp.append(col_dict)\n",
    "        elif i % 2 == 1:\n",
    "            temp[-1] = (prev_col, temp[-1], col_dict)\n",
    "            if i == (len(d.items())-1):\n",
    "                add_new_col(temp, ret)\n",
    "        else:\n",
    "            if col[0].split(\"-\")[:check_idx] != prev_col[0].split(\"-\")[:check_idx]:\n",
    "                add_new_col(temp, ret)\n",
    "                temp = [col_dict]\n",
    "            else:\n",
    "                temp.append(col_dict)\n",
    "                \n",
    "        prev_col = col\n",
    "        \n",
    "    return pd.DataFrame(ret)\n",
    "\n",
    "def table_wrapper(exp_name, grid_params, columns, rows, objs=None, caption=\"\",\n",
    "                  combine_method=None, additionals=None):\n",
    "    if objs is None:\n",
    "        objs = ['avg_pert']\n",
    "    t = \"\"\"\n",
    "\\\\begin{table}[h!]\n",
    "\\\\tiny\n",
    "\\\\centering\n",
    "\\\\setlength{\\\\tabcolsep}{1.5pt}\n",
    "\"\"\"\n",
    "    df = pd.DataFrame({})\n",
    "    if combine_method is None:\n",
    "        df = avg_pert_table(exp_name, grid_params, columns, rows, objs)\n",
    "        if additionals:\n",
    "            for fn in additionals:\n",
    "                df = fn(df)\n",
    "    else:\n",
    "        dfs = []\n",
    "        for g in grid_params:\n",
    "            df = avg_pert_table(exp_name, g, columns, rows, objs)\n",
    "            if additionals:\n",
    "                for fn in additionals:\n",
    "                    df = fn(df)\n",
    "            dfs.append(df)\n",
    "        df = pd.concat(dfs, axis=combine_method)\n",
    "    \n",
    "    if 'dataset' in rows:\n",
    "        df = dataset_stat_column(df, grid_param, columns, rows)\n",
    "    t += df.to_latex(escape=False)\n",
    "    t += \"\"\"\\\\caption{%s}\n",
    "\\\\label{table:%s_%s}\n",
    "\\\\end{table}\n",
    "\"\"\" % (caption, exp_name, objs[0])\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(df, grid_param):\n",
    "    # col = ['model', 'attack']\n",
    "    ret = OrderedDict()\n",
    "    tst_df = params_to_dataframe(grid_param, ['tst_score'])\n",
    "\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    models = set([c[0] for c, _ in d.items()])\n",
    "    \n",
    "    prev_col =None\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        new_col_dict = OrderedDict({})\n",
    "        if i == 0:\n",
    "            for row, _ in col_dict.items():\n",
    "                temp_df = tst_df[(tst_df['model'] == col[0].replace(\"-\", \"_\"))\n",
    "                                 & (tst_df['attack'] == 'blackbox') \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        elif '\\\\epsilon' in col[1]:\n",
    "            m = re.match(r\"(?P<attack>[a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", col[1])\n",
    "            attack_name = m.group(\"attack\")[:-9].replace(\"-\", \"_\") # remove '$epsilon$'\n",
    "            for row, row_val in col_dict.items():\n",
    "                if 'd' in col[0].split('-')[-1]:\n",
    "                    model_name = '%s-%d-%s' % ('-'.join(col[0].split('-')[:-1]),\n",
    "                                               int(float(row_val.replace(\"$\", \"\"))*100),\n",
    "                                               col[0].split('-')[-1],)\n",
    "                else:\n",
    "                    model_name = \"%s-%d\" % (col[0], int(float(row_val.replace(\"$\", \"\"))*100))\n",
    "                model_name = model_name.replace(\"-\", \"_\")\n",
    "                temp_df = tst_df[(tst_df['model'] == model_name)\n",
    "                                 & (tst_df['attack'] == attack_name) \n",
    "                                 & (tst_df['dataset'] == row[0].replace(\"-\", \"_\"))]\n",
    "                new_col_dict[row] = \"$%.2f$\" % temp_df['tst_score'].mean()\n",
    "            ret[(col[0], col[1].replace('-avg-pert $\\\\epsilon$', ' tst acc.'))] = new_col_dict\n",
    "            \n",
    "        prev_col = col\n",
    "        ret[col] = col_dict\n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "#params_to_dataframe(grid_param, ['trnX_len', 'aug_len']).groupby(['dataset', 'model'])['aug_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_imp(df):\n",
    "    ret = OrderedDict()\n",
    "    d = df.to_dict(into=OrderedDict)\n",
    "    \n",
    "    def add_new_col(col_list, ret):\n",
    "        new_col = {}\n",
    "        \n",
    "        for attack_name in [col_list[0][0][1], col_list[1][0][1]]:\n",
    "            temp = list(filter(lambda t: t[0][1] == attack_name, col_list))\n",
    "            imps = []\n",
    "            for c in temp:\n",
    "                imps.append([float(v.replace(\"$\", \"\")) if v != -1 else -1 for _, v in c[1].items()])\n",
    "            imps = (np.array(imps).T).argmax(axis=1)\n",
    "\n",
    "            new_col = {}\n",
    "            new_col_imp = {}\n",
    "            new_col_eps = {}\n",
    "            pcol = temp[0][0]\n",
    "            \n",
    "            if 'd' in pcol[0].split(\"-\")[-1]:\n",
    "                tt = pcol[0].split(\"-\")\n",
    "                tt.pop(-2)\n",
    "            else:\n",
    "                tt = pcol[0].split(\"-\")[:-1]\n",
    "            new_col_name = (\"-\".join(tt), pcol[1])\n",
    "            new_col_imp_name = (\"-\".join(tt), (\"%s imp.\" % pcol[1]))\n",
    "            new_col_eps_name = (\"-\".join(tt), (\"%s $\\\\epsilon$\" % pcol[1]))\n",
    "            for i, idx in enumerate(imps):\n",
    "                k, v = list(temp[idx][1].items())[i]\n",
    "                new_col[k] = v\n",
    "                k, v = list(temp[idx][2].items())[i]\n",
    "                new_col_imp[k] = v \n",
    "\n",
    "                if 'd' in temp[idx][0][0].split(\"-\")[-1]:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-2]) * 0.01))[1:]\n",
    "                else:\n",
    "                    new_col_eps[k] = \"$\" + (\"%.1f$\" % (float(temp[idx][0][0].split(\"-\")[-1]) * 0.01))[1:]\n",
    "\n",
    "            ret[new_col_eps_name] = new_col_eps\n",
    "            ret[new_col_name] = new_col\n",
    "            ret[new_col_imp_name] = new_col_imp\n",
    "    \n",
    "    prev_col = None\n",
    "    temp = []\n",
    "    for i, (col, col_dict) in enumerate(d.items()):\n",
    "        if 'd' in col[0].split(\"-\")[-1]:\n",
    "            check_idx = -2\n",
    "        else:\n",
    "            check_idx = -1\n",
    "            \n",
    "        if i == 0 or i == 1:\n",
    "            ret[col] = col_dict\n",
    "            continue\n",
    "            \n",
    "        if len(temp) == 0:\n",
    "            temp.append(col_dict)\n",
    "        elif i % 2 == 1:\n",
    "            temp[-1] = (prev_col, temp[-1], col_dict)\n",
    "            if i == (len(d.items())-1):\n",
    "                add_new_col(temp, ret)\n",
    "        else:\n",
    "            if col[0].split(\"-\")[:check_idx] != prev_col[0].split(\"-\")[:check_idx]:\n",
    "                add_new_col(temp, ret)\n",
    "                temp = [col_dict]\n",
    "            else:\n",
    "                temp.append(col_dict)\n",
    "                \n",
    "        prev_col = col\n",
    "        \n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\tiny\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{1.5pt}\n",
      "\\begin{tabular}{lrr|lll|ll|ll|lll}\n",
      "\\toprule\n",
      "                   & \\multicolumn{2}{l}{-} & \\multicolumn{3}{l}{1-NN} & \\multicolumn{3}{l}{3-NN} & \\multicolumn{2}{l}{DT-d5} & \\multicolumn{2}{l}{random-forest-100-d5} \\\\\n",
      "                   & \\# examples & \\# features & Cheng's & direct-k1 & opt & Cheng's & direct-k3 & our's & Cheng's & dt-attack-opt &    Cheng's & rf-attack-rev-100 \\\\\n",
      "\\midrule\n",
      "cancer &         683 &          10 &            $.339$ &             $.354$ &                $.137$ &            $.385$ &             $.403$ &                          $.204$ &            $.309$ &                 $.255$ &               $.425$ &                     $.383$ \\\\\n",
      "diabetes &         768 &           8 &            $.112$ &             $.176$ &                $.035$ &            $.143$ &             $.171$ &                          $.078$ &            $.133$ &                 $.085$ &               $.181$ &                     $.184$ \\\\\n",
      "f-mnist06 &        2200 &          25 &            $.162$ &             $.259$ &                $.034$ &            $.184$ &                 -1 &                          $.064$ &            $.160$ &                 $.104$ &               $.245$ &                     $.238$ \\\\\n",
      "f-mnist35 &        2200 &          25 &            $.269$ &             $.354$ &                $.089$ &            $.279$ &             $.355$ &                          $.111$ &            $.202$ &                 $.150$ &               $.220$ &                     $.325$ \\\\\n",
      "fourclass &         862 &           2 &            $.138$ &             $.144$ &                $.090$ &            $.141$ &             $.137$ &                          $.096$ &            $.194$ &                 $.137$ &               $.165$ &                     $.133$ \\\\\n",
      "halfmoon &        2200 &           2 &            $.129$ &             $.070$ &                $.059$ &            $.132$ &             $.105$ &                          $.096$ &            $.148$ &                 $.085$ &               $.182$ &                     $.149$ \\\\\n",
      "mnist17 &        2200 &          25 &            $.260$ &             $.330$ &                $.079$ &            $.264$ &                 -1 &                          $.098$ &            $.178$ &                 $.130$ &               $.243$ &                     $.276$ \\\\\n",
      "mnist35 &        2200 &          25 &            $.167$ &             $.329$ &                $.045$ &            $.198$ &             $.284$ &                          $.075$ &            $.166$ &                 $.116$ &               $.189$ &                     $.226$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Average perturbation distance (Linf) acorss classifiers.}\n",
      "\\label{table:compare_attacks_avg_pert}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_param, _ = compare_attacks()\n",
    "avg_caption = \"Average perturbation distance (Linf) acorss classifiers.\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          combine_method=1,\n",
    "                          objs=['avg_pert'], additionals=[])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllll\", \"lrr|lll|ll|ll|ll\")\n",
    "table_str = table_str.replace(\"-avg-pert\", \"\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all\", \"opt\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"our's\")\n",
    "table_str = table_str.replace(\"decision-tree\", \"DT\")\n",
    "table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"multicolumn{4}{l}\", \"multicolumn{4}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "print(table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'knn1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f7d57c5cc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n\u001b[1;32m      4\u001b[0m                           \u001b[0mobjs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_pert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                           additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtable_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([a-zA-Z_0-9'-]+) imp\\.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imp.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtable_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([a-zA-Z_0-9'-]+) tst acc\\.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tst acc.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4290ead266d1>\u001b[0m in \u001b[0;36mtable_wrapper\u001b[0;34m(exp_name, grid_params, columns, rows, objs, caption, combine_method, additionals)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madditionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4290ead266d1>\u001b[0m in \u001b[0;36mmax_imp\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcheck_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprev_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcheck_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0madd_new_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4290ead266d1>\u001b[0m in \u001b[0;36madd_new_col\u001b[0;34m(col_list, ret)\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mnew_col_eps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"$\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%.1f$\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0mnew_col_eps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"$\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%.1f$\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_col_eps_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_col_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'knn1'"
     ]
    }
   ],
   "source": [
    "_, exp_name, grid_param, _ = nn_k1_robustness()\n",
    "avg_caption = \"1-NN average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"nnopt-k1-all\", \"opt\")\n",
    "table_str = table_str.replace(\"robustv1-nn-k1\", \"1-NN with adversarial pruning\")\n",
    "table_str = table_str.replace(\"knn1\", \"1-NN\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_k3_robustness()\n",
    "avg_caption = \"3-NN average perturbation distance (Linf)\"\n",
    "#table_str = table_wrapper(exp_name, grid_param, ['model', 'attack'], ['dataset'], caption=avg_caption, additionals=[cmp_ratio])\n",
    "#table_str = re.sub(\"([a-zA-Z_0-9'-]*) imp\\.\", \"imp.\", table_str)\n",
    "#write_to_tex(table_str, exp_name + '_table.tex')\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"rev-nnopt-k3-50-region\", \"our-50\")\n",
    "table_str = table_str.replace(\"robustv1-nn-k3\", \"3-NN with adversarial pruning\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"knn3\", \"3-NN\")\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_robustness()\n",
    "avg_caption = \"Random forest average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"lrrlllllllllllllllllllllllllll\", \"lcc|lll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "table_str = table_str.replace(\"blackbox\", \"Cheng's\")\n",
    "table_str = table_str.replace(\"random-forest-100-d5\", \"random forest\")\n",
    "table_str = table_str.replace(\"robust-rf-100-d5\", \"random forest with robust splitting\")\n",
    "table_str = table_str.replace(\"robustv1-rf-100-d5\", \"random forest with adversarial pruning\")\n",
    "\n",
    "table_str = table_str.replace(\"multicolumn{8}{l}\", \"multicolumn{8}{|c}\")\n",
    "table_str = table_str.replace(\"multicolumn{3}{l}\", \"multicolumn{3}{|c}\")\n",
    "for k, v in variable_name['dataset'].items():\n",
    "    table_str = re.sub(k.replace('_', '-'), v, table_str)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = dt_robustness()\n",
    "avg_caption = \"Decision tree average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['model', 'attack'], ['dataset'], caption=avg_caption, \n",
    "                          objs=['avg_pert'],\n",
    "                          additionals=[cmp_ratio, max_imp, partial(model_acc, grid_param=grid_param)])\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) imp\\.\", \"imp.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) tst acc\\.\", \"tst acc.\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+) \\$\\\\epsilon\\$\", \"$\\\\epsilon$\", table_str)\n",
    "table_str = table_str.replace(\"llllllllllllllllllllllllllll\", \"llll|llll|llll|llll|llll|llll|llll\")\n",
    "table_str = table_str.replace(\"dt-attack-opt\", \"opt\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fns = [dt_robustness_figs, nn_k1_robustness_figs, nn_k3_robustness_figs,]\n",
    "def get_label_name(name):\n",
    "    if 'robustv1' in name:\n",
    "        return \"adversarial pruning\"\n",
    "    elif 'robust' in name:\n",
    "        return \"robust splitting\"\n",
    "    elif 'decision_tree' in name:\n",
    "        return \"decision tree\"\n",
    "    elif 'knn1' in name:\n",
    "        return \"1-NN\"\n",
    "    elif 'knn3' in name:\n",
    "        return \"3-NN\"\n",
    "        \n",
    "    return name\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    \n",
    "    plot_result(df, exp_name, control, variables, get_title=lambda x: '',\n",
    "                get_label_name=get_label_name, show_plot=show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "\n",
    "for fn in exp_fns:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    fig_str = compare_nn_plots(exp_name, grid_param, show_plot=True)\n",
    "#write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = compare_nns()\n",
    "\n",
    "def compare_nn_plots(exp_name, grid_param, caption='', show_plot=True):\n",
    "    df = params_to_dataframe(grid_param)\n",
    "    datasets = set.union(*[set(g['dataset']) for g in grid_param]) if isinstance(grid_param, list) else grid_param['dataset']\n",
    "\n",
    "    control = {\n",
    "        'dataset': datasets,\n",
    "        'ord': grid_param[0]['ord'],\n",
    "    }\n",
    "    variables = ['model']\n",
    "    plot_result(df, exp_name, control, variables, show_plot=show_plot)\n",
    "    return result_latex_figs(exp_name, control, caption)\n",
    "fig_str = compare_nn_plots(exp_name, grid_param, show_plot=True)\n",
    "write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash ./sync_report.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_k1_optimality_figs()\n",
    "df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "datasets = union_param_key(grid_param, 'dataset')\n",
    "for dataset in datasets:\n",
    "    temp_df = df[(df['dataset'] == dataset)]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(dataset)\n",
    "    x = []\n",
    "    for k, v in temp_df.groupby(\"attack\"):\n",
    "        avg_pert = v['avg_pert'].mean()\n",
    "        if k == 'blackbox':\n",
    "            bb_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='Cheng', colors='c')\n",
    "        elif k.split('_')[-1] == 'all':\n",
    "            opt_avg = avg_pert\n",
    "            ax.hlines(avg_pert, xmin=0, xmax=100, label='opt')\n",
    "        elif k.split('_')[-1] == 'rev':\n",
    "            x.append((100, avg_pert))\n",
    "        else:\n",
    "            if k.split('_')[-1] != 'region':\n",
    "                x.append((int(k.split('_')[-1]), avg_pert))\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "    x = sorted(x, key=lambda t: t[0])\n",
    "    x, y = zip(*x)\n",
    "    ax.plot(x, y)\n",
    "    set_plot(fig, ax)\n",
    "    ax.set_ylim(opt_avg-0.03, max(list(y) + [bb_avg])+0.03)\n",
    "    ax.set_xlim(0, 100)\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "    #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in [nn_k1_robustness_figs, nn_k3_robustness_figs]:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    df = params_to_dataframe(grid_param, ['avg_pert'])\n",
    "    datasets = union_param_key(grid_param, 'dataset')\n",
    "    for dataset in datasets:\n",
    "        temp_df = df[(df['dataset'] == dataset)]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(dataset)\n",
    "        x = []\n",
    "        for k, v in temp_df.groupby(\"attack\"):\n",
    "            avg_pert = v['avg_pert'].mean()\n",
    "            if k == 'blackbox':\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='Cheng')\n",
    "            elif k.split('_')[-1] == 'all':\n",
    "                opt_pert = avg_pert\n",
    "                ax.hlines(avg_pert, xmin=0, xmax=50, label='opt')\n",
    "            else:\n",
    "                x.append((int(k.split('_')[-2]), avg_pert))\n",
    "        x = sorted(x, key=lambda t: t[0])\n",
    "        x, y = zip(*x)\n",
    "        ax.plot(x, y)\n",
    "        set_plot(fig, ax)\n",
    "        ax.set_ylim(opt_pert-0.03, max(y)+0.03)\n",
    "        ax.set_xlim(0, 50)\n",
    "        #ax.set_xscale('log')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.eps', format='eps')\n",
    "        #plt.savefig(f'./figs/{exp_name}_{dataset}_{ord}.png', format='png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = rf_optimality()\n",
    "avg_caption = \"RF average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"rf-attack-rev-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, exp_name, grid_param, _ = nn_optimality()\n",
    "avg_caption = \"3NN average perturbation distance (Linf)\"\n",
    "table_str = table_wrapper(exp_name, grid_param,\n",
    "                          ['n_samples', 'n_features', 'n_classes', 'model', 'attack'], ['dataset'],\n",
    "                          caption=avg_caption, combine_method=1)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-avg-pert\", r\"\\1\", table_str)\n",
    "table_str = re.sub(r\"([a-zA-Z_0-9'-]+)-region\", r\"\\1\", table_str)\n",
    "table_str = table_str.replace(\"nnopt-k3-\", \"our-\")\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, grid_param, _ = nn_k1_robustness()\n",
    "datasets = union_param_key(grid_param, 'dataset')\n",
    "exp_name = \"dataset-stats\"\n",
    "grid_param = {\n",
    "    \"dataset\": datasets,\n",
    "}\n",
    "caption = \"Data set statistics\"\n",
    "table_str = table_wrapper(exp_name, grid_param, ['n_samples', 'n_features', 'n_classes'], ['dataset'], caption=caption)\n",
    "write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [rf_attack, opt_of_rf_attack, robust_rf]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    #columns = ['blackbox', 'rf_attack_rev_20', 'rf_attack_rev_100']\n",
    "    table_str = table_wrapper(exp_name, grid_param, ['attack'], ['dataset'], caption=avg_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(grid_param)\n",
    "    variables = grid_param[0]['attack']\n",
    "    #variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    #print(table_str)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [nn_k1, nn_k3, nn_k5, nn_k7, opt_of_nnopt]\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    print(exp_name)\n",
    "    fig_str = knn_attack_plots(exp_name, grid_param, show_plot=False)\n",
    "    write_to_tex(fig_str, exp_name + '_fig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_experiments = [robust_nn_k1, robust_nn_k3]\n",
    "avg_caption = \"average purturbation distance (Linf)\"\n",
    "miss_caption = \"\\\\# of data algorithms is not able to generate successful attack (total 100 data points)\"\n",
    "for fn in nn_experiments:\n",
    "    _, exp_name, grid_param, _ = fn()\n",
    "    variables = grid_param[0]['attack']\n",
    "    variables = list(filter(lambda v: 'kernelsub' not in v and 'direct' not in v, variables))\n",
    "    print(variables)\n",
    "    table_str = table_wrapper(exp_name, grid_param, variables, caption=avg_caption)\n",
    "    table_str += table_wrapper(exp_name, grid_param, variables, obj='missed_count', caption=miss_caption)\n",
    "    write_to_tex(table_str, exp_name + '_table.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnattack.models.robust_nn.eps_separation import build_collision_graph, find_min_cover\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=3)\n",
    "\n",
    "auto_var.set_variable_value(\"random_seed\", 0)\n",
    "np.random.seed(0)\n",
    "X, y, _ = auto_var.get_var_with_argument(\"dataset\", \"mnist17_2200\")\n",
    "pts = PCA().fit_transform(X)\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "pts = MinMaxScaler().fit_transform(pts)\n",
    "\n",
    "nn.fit(pts)\n",
    "y_pts = [1 if i>0 else -1 for i in y]\n",
    "adj_lst, graph = build_collision_graph(0.15, pts, y_pts, np.inf)\n",
    "matching, min_cover = find_min_cover(graph, adj_lst, y_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[list(min_cover)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in min_cover:\n",
    "    _, idx = nn.kneighbors([pts[i]])\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.savefig(f'/home/arbiter/figs/{i}.png', format='png')\n",
    "    plt.close()\n",
    "    mkdir_p(f'/home/arbiter/figs/{i}')\n",
    "    for j in idx[0]:\n",
    "        print(j, X.shape)\n",
    "        plt.imshow(X[j].reshape(28, 28))\n",
    "        plt.savefig(f'/home/arbiter/figs/{i}/{j}.png', format='png')\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
